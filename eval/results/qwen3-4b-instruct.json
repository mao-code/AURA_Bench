{
  "qwen3-4b-instruct": {
    "hf_repo": "Qwen/Qwen3-4B-Instruct-2507",
    "representation": {
      "recall@1": 0.27420948616600793,
      "success@1": 0.283596837944664,
      "ndcg@1": 0.283596837944664,
      "recall@3": 0.39377470355731226,
      "success@3": 0.40019762845849804,
      "ndcg@3": 0.34676948986661027,
      "recall@5": 0.4762845849802372,
      "success@5": 0.48320158102766797,
      "ndcg@5": 0.38099332688131127,
      "recall@10": 0.5810276679841897,
      "success@10": 0.5869565217391305,
      "ndcg@10": 0.4152258611961522,
      "mrr": 0.38298111931042417,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.15763546798029557,
          "success@1": 0.1724137931034483,
          "ndcg@1": 0.1724137931034483,
          "recall@3": 0.25862068965517243,
          "success@3": 0.270935960591133,
          "ndcg@3": 0.22069305784320142,
          "recall@5": 0.3275862068965517,
          "success@5": 0.3399014778325123,
          "ndcg@5": 0.24845196452043214,
          "recall@10": 0.4236453201970443,
          "success@10": 0.43349753694581283,
          "ndcg@10": 0.2801772833652244,
          "mrr": 0.2669511042014017,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.33098591549295775,
          "success@1": 0.3380281690140845,
          "ndcg@1": 0.3380281690140845,
          "recall@3": 0.528169014084507,
          "success@3": 0.5352112676056338,
          "ndcg@3": 0.4477678165480082,
          "recall@5": 0.6549295774647887,
          "success@5": 0.6619718309859155,
          "ndcg@5": 0.49989167597484097,
          "recall@10": 0.7253521126760564,
          "success@10": 0.7323943661971831,
          "ndcg@10": 0.5227780681593853,
          "mrr": 0.4751320540035926,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.2740963855421687,
          "success@1": 0.28313253012048195,
          "ndcg@1": 0.28313253012048195,
          "recall@3": 0.3855421686746988,
          "success@3": 0.3855421686746988,
          "ndcg@3": 0.34204619799748437,
          "recall@5": 0.43373493975903615,
          "success@5": 0.43373493975903615,
          "ndcg@5": 0.36148170227695964,
          "recall@10": 0.5180722891566265,
          "success@10": 0.5180722891566265,
          "ndcg@10": 0.38854621814813917,
          "mrr": 0.365788056436924,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.3467741935483871,
          "success@1": 0.3548387096774194,
          "ndcg@1": 0.3548387096774194,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.44008997615207657,
          "recall@5": 0.5806451612903226,
          "success@5": 0.5806451612903226,
          "ndcg@5": 0.4741151219509171,
          "recall@10": 0.6612903225806451,
          "success@10": 0.6612903225806451,
          "ndcg@10": 0.5005565530190527,
          "mrr": 0.4632825902312998,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.297029702970297,
          "success@1": 0.31683168316831684,
          "ndcg@1": 0.31683168316831684,
          "recall@3": 0.46534653465346537,
          "success@3": 0.4752475247524752,
          "ndcg@3": 0.40275611665488237,
          "recall@5": 0.5643564356435643,
          "success@5": 0.5643564356435643,
          "ndcg@5": 0.44479456819434643,
          "recall@10": 0.6732673267326733,
          "success@10": 0.6732673267326733,
          "ndcg@10": 0.47985021751873513,
          "mrr": 0.43247021531067914,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.35,
          "success@1": 0.35,
          "ndcg@1": 0.35,
          "recall@3": 0.525,
          "success@3": 0.525,
          "ndcg@3": 0.4473197315178593,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.5194013478677892,
          "recall@10": 0.75,
          "success@10": 0.75,
          "ndcg@10": 0.5355331482034369,
          "mrr": 0.4812364243943191,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.5294117647058824,
          "success@1": 0.5294117647058824,
          "ndcg@1": 0.5294117647058824,
          "recall@3": 0.6176470588235294,
          "success@3": 0.6470588235294118,
          "ndcg@3": 0.5845590205855404,
          "recall@5": 0.7352941176470589,
          "success@5": 0.7647058823529411,
          "ndcg@5": 0.6352268509471161,
          "recall@10": 0.8823529411764706,
          "success@10": 0.8823529411764706,
          "ndcg@10": 0.6854139455181484,
          "mrr": 0.631261328060636,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.29891304347826086,
          "success@1": 0.30434782608695654,
          "ndcg@1": 0.30434782608695654,
          "recall@3": 0.375,
          "success@3": 0.3804347826086957,
          "ndcg@3": 0.3424558310160851,
          "recall@5": 0.44565217391304346,
          "success@5": 0.45652173913043476,
          "ndcg@5": 0.372168978402302,
          "recall@10": 0.6086956521739131,
          "success@10": 0.6086956521739131,
          "ndcg@10": 0.4262408555659078,
          "mrr": 0.387588547472112,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.20676691729323307,
          "success@1": 0.21052631578947367,
          "ndcg@1": 0.21052631578947367,
          "recall@3": 0.30451127819548873,
          "success@3": 0.3082706766917293,
          "ndcg@3": 0.2633808681786892,
          "recall@5": 0.41353383458646614,
          "success@5": 0.42105263157894735,
          "ndcg@5": 0.3087237060025011,
          "recall@10": 0.5676691729323309,
          "success@10": 0.5789473684210527,
          "ndcg@10": 0.3598489246902069,
          "mrr": 0.31613980701821903,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.3700787401574803,
          "success@1": 0.3779527559055118,
          "ndcg@1": 0.3779527559055118,
          "recall@3": 0.47244094488188976,
          "success@3": 0.48031496062992124,
          "ndcg@3": 0.4348741600382895,
          "recall@5": 0.531496062992126,
          "success@5": 0.5433070866141733,
          "ndcg@5": 0.4601348676638344,
          "recall@10": 0.6220472440944882,
          "success@10": 0.6377952755905512,
          "ndcg@10": 0.48873906300061176,
          "mrr": 0.4633226204102419,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.2743682310469314,
          "success@1": 0.2815884476534296,
          "ndcg@1": 0.2815884476534296,
          "recall@3": 0.4043321299638989,
          "success@3": 0.41155234657039713,
          "ndcg@3": 0.35248959186287576,
          "recall@5": 0.463898916967509,
          "success@5": 0.4729241877256318,
          "ndcg@5": 0.3774314831543895,
          "recall@10": 0.575812274368231,
          "success@10": 0.5812274368231047,
          "ndcg@10": 0.4141873769648383,
          "mrr": 0.38393967444712834,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.07692307692307693,
          "success@1": 0.11538461538461539,
          "ndcg@1": 0.11538461538461539,
          "recall@3": 0.19230769230769232,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.15556644188679083,
          "recall@5": 0.2692307692307692,
          "success@5": 0.3076923076923077,
          "ndcg@5": 0.18785264345322777,
          "recall@10": 0.3269230769230769,
          "success@10": 0.36538461538461536,
          "ndcg@10": 0.20810829245834864,
          "mrr": 0.2265770271284145,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.3269230769230769,
          "success@1": 0.3269230769230769,
          "ndcg@1": 0.3269230769230769,
          "recall@3": 0.4423076923076923,
          "success@3": 0.4423076923076923,
          "ndcg@3": 0.39468690412088137,
          "recall@5": 0.5576923076923077,
          "success@5": 0.5576923076923077,
          "ndcg@5": 0.44353758869014115,
          "recall@10": 0.6346153846153846,
          "success@10": 0.6346153846153846,
          "ndcg@10": 0.46920706049528094,
          "mrr": 0.4283058587877417,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.42857142857142855,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.3758471076530654,
          "recall@5": 0.42857142857142855,
          "success@5": 0.42857142857142855,
          "ndcg@5": 0.3758471076530654,
          "recall@10": 0.5714285714285714,
          "success@10": 0.5714285714285714,
          "ndcg@10": 0.423466155272113,
          "mrr": 0.393367603451637,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.19230769230769232,
          "success@1": 0.20512820512820512,
          "ndcg@1": 0.20512820512820512,
          "recall@3": 0.32051282051282054,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2693829859866623,
          "recall@5": 0.4230769230769231,
          "success@5": 0.4358974358974359,
          "ndcg@5": 0.31018388290402177,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.3459734765081684,
          "mrr": 0.31239295620051744,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.7142857142857143,
          "success@3": 0.7142857142857143,
          "ndcg@3": 0.7142857142857143,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.7695504010335059,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.7695504010335059,
          "mrr": 0.7431350750416899,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.26785714285714285,
          "success@3": 0.26785714285714285,
          "ndcg@3": 0.24107142857142858,
          "recall@5": 0.375,
          "success@5": 0.375,
          "ndcg@5": 0.28408507759080276,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.3241546924002316,
          "mrr": 0.28756545943204026,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.2222222222222222,
          "success@1": 0.2222222222222222,
          "ndcg@1": 0.2222222222222222,
          "recall@3": 0.28888888888888886,
          "success@3": 0.28888888888888886,
          "ndcg@3": 0.26137465571428703,
          "recall@5": 0.5222222222222223,
          "success@5": 0.5333333333333333,
          "ndcg@5": 0.3580794323612262,
          "recall@10": 0.6111111111111112,
          "success@10": 0.6222222222222222,
          "ndcg@10": 0.3865157733039646,
          "mrr": 0.33221481948489,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.3,
          "success@1": 0.3,
          "ndcg@1": 0.3,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.325,
          "recall@5": 0.45,
          "success@5": 0.45,
          "ndcg@5": 0.3680676558073393,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.42035504118480815,
          "mrr": 0.37757217677671434,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.4827586206896552,
          "success@1": 0.4827586206896552,
          "ndcg@1": 0.4827586206896552,
          "recall@3": 0.5517241379310345,
          "success@3": 0.5517241379310345,
          "ndcg@3": 0.5172413793103449,
          "recall@5": 0.5862068965517241,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.5305811312839497,
          "recall@10": 0.6896551724137931,
          "success@10": 0.6896551724137931,
          "ndcg@10": 0.5666413970615145,
          "mrr": 0.5403089461009651,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2971220730654774,
          "recall@5": 0.375,
          "success@5": 0.375,
          "ndcg@5": 0.3150669296518688,
          "recall@10": 0.4166666666666667,
          "success@10": 0.4166666666666667,
          "ndcg@10": 0.32990889578136967,
          "mrr": 0.3209987355382364,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7261859507142916,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7261859507142916,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7261859507142916,
          "mrr": 0.7009132420091324,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.4,
          "success@1": 0.4,
          "ndcg@1": 0.4,
          "recall@3": 0.4,
          "success@3": 0.4,
          "ndcg@3": 0.4,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.43868528072345414,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.43868528072345414,
          "mrr": 0.44299130178387147,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.42857142857142855,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.33078069668367555,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.3584130400575714,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.43147545818433486,
          "mrr": 0.35512504182000665,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.27586206896551724,
          "success@1": 0.29310344827586204,
          "ndcg@1": 0.29310344827586204,
          "recall@3": 0.47413793103448276,
          "success@3": 0.4827586206896552,
          "ndcg@3": 0.3993885159272271,
          "recall@5": 0.5718390804597702,
          "success@5": 0.5747126436781609,
          "ndcg@5": 0.44061249299804256,
          "recall@10": 0.6982758620689655,
          "success@10": 0.7011494252873564,
          "ndcg@10": 0.4817538415885418,
          "mrr": 0.42882126471210685,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.5218216255952429,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.5862970934676666,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.641852649023222,
          "mrr": 0.5293650793650794,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.014925373134328358,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2103099178571525,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.2103099178571525,
          "recall@10": 0.3333333333333333,
          "success@10": 0.3333333333333333,
          "ndcg@10": 0.2103099178571525,
          "mrr": 0.1777695988222304,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.010393154784179794,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.009900990099009901,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.07142857142857142,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.03125,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.23076923076923078,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.3076923076923077,
          "success@3": 0.3076923076923077,
          "ndcg@3": 0.2692307692307692,
          "recall@5": 0.38461538461538464,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.29898867747958013,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.352030255975069,
          "mrr": 0.3010241176404436,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3562071871080222,
          "mrr": 0.16666666666666666,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.016666666666666666,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.08333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.3181818181818182,
          "success@1": 0.36363636363636365,
          "ndcg@1": 0.36363636363636365,
          "recall@3": 0.45454545454545453,
          "success@3": 0.45454545454545453,
          "ndcg@3": 0.4136955038836041,
          "recall@5": 0.45454545454545453,
          "success@5": 0.45454545454545453,
          "ndcg@5": 0.4136955038836041,
          "recall@10": 0.5454545454545454,
          "success@10": 0.5454545454545454,
          "ndcg@10": 0.4423741290459431,
          "mrr": 0.4371769671948295,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.04730798551553268,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.00909090909090909,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.047619047619047616,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.10256410256410256,
          "success@1": 0.10256410256410256,
          "ndcg@1": 0.10256410256410256,
          "recall@3": 0.23076923076923078,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.17673818617216341,
          "recall@5": 0.358974358974359,
          "success@5": 0.358974358974359,
          "ndcg@5": 0.22970575767701626,
          "recall@10": 0.4358974358974359,
          "success@10": 0.4358974358974359,
          "ndcg@10": 0.2522483127616255,
          "mrr": 0.2203307681404205,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.7,
          "success@1": 0.72,
          "ndcg@1": 0.72,
          "recall@3": 0.76,
          "success@3": 0.76,
          "ndcg@3": 0.7420260217087857,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7575001339981675,
          "recall@10": 0.88,
          "success@10": 0.88,
          "ndcg@10": 0.7837896213090475,
          "mrr": 0.764858858858859,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.1505149978319906,
          "mrr": 0.06093189964157706,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.08181818181818182,
          "success@1": 0.09090909090909091,
          "ndcg@1": 0.09090909090909091,
          "recall@3": 0.17272727272727273,
          "success@3": 0.18181818181818182,
          "ndcg@3": 0.138852112855478,
          "recall@5": 0.23636363636363636,
          "success@5": 0.2545454545454545,
          "ndcg@5": 0.16585945169458025,
          "recall@10": 0.37272727272727274,
          "success@10": 0.4,
          "ndcg@10": 0.208967923001764,
          "mrr": 0.18435122384518407,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.8368098770740497,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8471336208711173,
          "mrr": 0.8376931700864628,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.32041343669250644,
          "success@1": 0.3281653746770026,
          "ndcg@1": 0.3281653746770026,
          "recall@3": 0.47674418604651164,
          "success@3": 0.48320413436692505,
          "ndcg@3": 0.4161031463356969,
          "recall@5": 0.58656330749354,
          "success@5": 0.5917312661498708,
          "ndcg@5": 0.46182671846928514,
          "recall@10": 0.6757105943152455,
          "success@10": 0.6795865633074936,
          "ndcg@10": 0.4910488565572666,
          "mrr": 0.44826891793418144,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.25047801147227533,
          "success@1": 0.25812619502868067,
          "ndcg@1": 0.25812619502868067,
          "recall@3": 0.35564053537284895,
          "success@3": 0.361376673040153,
          "ndcg@3": 0.3124084710245378,
          "recall@5": 0.42638623326959846,
          "success@5": 0.4340344168260038,
          "ndcg@5": 0.34167126626844313,
          "recall@10": 0.5458891013384322,
          "success@10": 0.5525812619502868,
          "ndcg@10": 0.38063690687308993,
          "mrr": 0.34989364220454516,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.21333333333333335,
          "success@1": 0.22666666666666666,
          "ndcg@1": 0.22666666666666666,
          "recall@3": 0.25333333333333335,
          "success@3": 0.25333333333333335,
          "ndcg@3": 0.24135068113919053,
          "recall@5": 0.30666666666666664,
          "success@5": 0.30666666666666664,
          "ndcg@5": 0.2631514642140688,
          "recall@10": 0.3933333333333333,
          "success@10": 0.4,
          "ndcg@10": 0.29106756648047205,
          "mrr": 0.28065301334927595,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.24074074074074073,
          "success@1": 0.2962962962962963,
          "ndcg@1": 0.2962962962962963,
          "recall@3": 0.3333333333333333,
          "success@3": 0.37037037037037035,
          "ndcg@3": 0.3114027659934081,
          "recall@5": 0.3333333333333333,
          "success@5": 0.37037037037037035,
          "ndcg@5": 0.3114027659934081,
          "recall@10": 0.42592592592592593,
          "success@10": 0.4444444444444444,
          "ndcg@10": 0.3433146023030559,
          "mrr": 0.37235076397957795,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.0885956644674835,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.09172413793103448,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.05211267605633803,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.09228915662650602,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.05741935483870968,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06217821782178218,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.0345,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.015294117647058824,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.06391304347826086,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.06887218045112782,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06173228346456693,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.0820216606498195,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.040769230769230766,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.09230769230769231,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.14285714285714285,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.10564102564102563,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.10526315789473684,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.09466666666666666,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.1,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.08758620689655172,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.08583333333333333,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.064,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.102,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.08,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.08428571428571428,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.059782608695652176,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.013333333333333334,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.1,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.10666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.11333333333333333,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.15384615384615385,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.04727272727272727,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.25,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.07179487179487179,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.07692307692307693,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.09,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.07490909090909091,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.03571428571428571,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.07974160206718346,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.08848948374760994,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.11392405063291139,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.10222222222222223,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}