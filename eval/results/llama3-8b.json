{
  "llama3-8b": {
    "hf_repo": "meta-llama/Meta-Llama-3-8B",
    "representation": {
      "recall@1": 0.32767489711934156,
      "success@1": 0.3343621399176955,
      "ndcg@1": 0.3343621399176955,
      "recall@3": 0.4696502057613169,
      "success@3": 0.47530864197530864,
      "ndcg@3": 0.41130391533953603,
      "recall@5": 0.5390946502057613,
      "success@5": 0.5442386831275721,
      "ndcg@5": 0.44006479069435295,
      "recall@10": 0.6568930041152263,
      "success@10": 0.661522633744856,
      "ndcg@10": 0.4790202686272993,
      "mrr": 0.4390807975127087,
      "num_queries": 972,
      "num_candidates": 1006,
      "by_language": {
        "ar": {
          "recall@1": 0.20105820105820105,
          "success@1": 0.21164021164021163,
          "ndcg@1": 0.21164021164021163,
          "recall@3": 0.28835978835978837,
          "success@3": 0.30158730158730157,
          "ndcg@3": 0.2536377256591941,
          "recall@5": 0.3492063492063492,
          "success@5": 0.36507936507936506,
          "ndcg@5": 0.2789408294888872,
          "recall@10": 0.5026455026455027,
          "success@10": 0.5132275132275133,
          "ndcg@10": 0.33013794428253185,
          "mrr": 0.3038702482127244,
          "num_queries": 189,
          "num_candidates": 1006
        },
        "de": {
          "recall@1": 0.5230769230769231,
          "success@1": 0.5230769230769231,
          "ndcg@1": 0.5230769230769231,
          "recall@3": 0.7230769230769231,
          "success@3": 0.7230769230769231,
          "ndcg@3": 0.6391913542857178,
          "recall@5": 0.7846153846153846,
          "success@5": 0.7846153846153846,
          "ndcg@5": 0.6656945270902345,
          "recall@10": 0.8769230769230769,
          "success@10": 0.8769230769230769,
          "ndcg@10": 0.6958824669478586,
          "mrr": 0.6445594208401608,
          "num_queries": 65,
          "num_candidates": 1006
        },
        "en": {
          "recall@1": 0.3150684931506849,
          "success@1": 0.3219178082191781,
          "ndcg@1": 0.3219178082191781,
          "recall@3": 0.4520547945205479,
          "success@3": 0.4520547945205479,
          "ndcg@3": 0.397747650978476,
          "recall@5": 0.5273972602739726,
          "success@5": 0.5273972602739726,
          "ndcg@5": 0.4280947460670743,
          "recall@10": 0.6301369863013698,
          "success@10": 0.6301369863013698,
          "ndcg@10": 0.4626283414879051,
          "mrr": 0.42377558943894356,
          "num_queries": 146,
          "num_candidates": 1006
        },
        "fr": {
          "recall@1": 0.3951612903225806,
          "success@1": 0.4032258064516129,
          "ndcg@1": 0.4032258064516129,
          "recall@3": 0.5967741935483871,
          "success@3": 0.5967741935483871,
          "ndcg@3": 0.5126706213133668,
          "recall@5": 0.6451612903225806,
          "success@5": 0.6451612903225806,
          "ndcg@5": 0.5320961402253422,
          "recall@10": 0.7741935483870968,
          "success@10": 0.7741935483870968,
          "ndcg@10": 0.5746904616246702,
          "mrr": 0.5233570321132622,
          "num_queries": 62,
          "num_candidates": 1006
        },
        "es": {
          "recall@1": 0.39603960396039606,
          "success@1": 0.4158415841584158,
          "ndcg@1": 0.4158415841584158,
          "recall@3": 0.5693069306930693,
          "success@3": 0.5841584158415841,
          "ndcg@3": 0.5059804457898133,
          "recall@5": 0.6633663366336634,
          "success@5": 0.6633663366336634,
          "ndcg@5": 0.5455015118126584,
          "recall@10": 0.7524752475247525,
          "success@10": 0.7524752475247525,
          "ndcg@10": 0.5758445320527295,
          "mrr": 0.5334598612015823,
          "num_queries": 101,
          "num_candidates": 1006
        },
        "hi": {
          "recall@1": 0.475,
          "success@1": 0.475,
          "ndcg@1": 0.475,
          "recall@3": 0.775,
          "success@3": 0.775,
          "ndcg@3": 0.6446394630357186,
          "recall@5": 0.85,
          "success@5": 0.85,
          "ndcg@5": 0.6758446111202518,
          "recall@10": 0.875,
          "success@10": 0.875,
          "ndcg@10": 0.6847497907979524,
          "mrr": 0.6292610883739915,
          "num_queries": 40,
          "num_candidates": 1006
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.6176470588235294,
          "success@3": 0.6470588235294118,
          "ndcg@3": 0.5040254766779791,
          "recall@5": 0.7941176470588235,
          "success@5": 0.8235294117647058,
          "ndcg@5": 0.5774493545239396,
          "recall@10": 0.9411764705882353,
          "success@10": 0.9411764705882353,
          "ndcg@10": 0.6297819228180627,
          "mrr": 0.5362745098039216,
          "num_queries": 17,
          "num_candidates": 1006
        },
        "ko": {
          "recall@1": 0.32065217391304346,
          "success@1": 0.32608695652173914,
          "ndcg@1": 0.32608695652173914,
          "recall@3": 0.3967391304347826,
          "success@3": 0.40217391304347827,
          "ndcg@3": 0.36419496145086777,
          "recall@5": 0.4945652173913043,
          "success@5": 0.5,
          "ndcg@5": 0.4056646032705686,
          "recall@10": 0.6086956521739131,
          "success@10": 0.6195652173913043,
          "ndcg@10": 0.44274984650129867,
          "mrr": 0.40931718551683266,
          "num_queries": 92,
          "num_candidates": 1006
        },
        "ru": {
          "recall@1": 0.23308270676691728,
          "success@1": 0.23308270676691728,
          "ndcg@1": 0.23308270676691728,
          "recall@3": 0.424812030075188,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.33982067927029413,
          "recall@5": 0.48872180451127817,
          "success@5": 0.49624060150375937,
          "ndcg@5": 0.36606400132266614,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6466165413533834,
          "ndcg@10": 0.4155810254115534,
          "mrr": 0.35898896676769343,
          "num_queries": 133,
          "num_candidates": 1006
        },
        "zh": {
          "recall@1": 0.39763779527559057,
          "success@1": 0.4015748031496063,
          "ndcg@1": 0.4015748031496063,
          "recall@3": 0.47244094488188976,
          "success@3": 0.47244094488188976,
          "ndcg@3": 0.4431935316647933,
          "recall@5": 0.5118110236220472,
          "success@5": 0.5118110236220472,
          "ndcg@5": 0.45911409495495403,
          "recall@10": 0.6141732283464567,
          "success@10": 0.6220472440944882,
          "ndcg@10": 0.4924636101712987,
          "mrr": 0.46905554358891904,
          "num_queries": 127,
          "num_candidates": 1006
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.34115523465703973,
          "success@1": 0.34657039711191334,
          "ndcg@1": 0.34657039711191334,
          "recall@3": 0.48375451263537905,
          "success@3": 0.49097472924187724,
          "ndcg@3": 0.42338070885716383,
          "recall@5": 0.5667870036101083,
          "success@5": 0.5740072202166066,
          "ndcg@5": 0.4579718148333618,
          "recall@10": 0.6859205776173285,
          "success@10": 0.6895306859205776,
          "ndcg@10": 0.4983892561274879,
          "mrr": 0.4547777697789953,
          "num_queries": 277,
          "num_candidates": 1006
        },
        "poetry": {
          "recall@1": 0.13157894736842105,
          "success@1": 0.15789473684210525,
          "ndcg@1": 0.15789473684210525,
          "recall@3": 0.34210526315789475,
          "success@3": 0.3684210526315789,
          "ndcg@3": 0.2600248198260054,
          "recall@5": 0.40789473684210525,
          "success@5": 0.4473684210526316,
          "ndcg@5": 0.2896384081245771,
          "recall@10": 0.5921052631578947,
          "success@10": 0.631578947368421,
          "ndcg@10": 0.3529616084258054,
          "mrr": 0.31111380959122087,
          "num_queries": 38,
          "num_candidates": 1006
        },
        "social_media/politics": {
          "recall@1": 0.4423076923076923,
          "success@1": 0.4423076923076923,
          "ndcg@1": 0.4423076923076923,
          "recall@3": 0.5865384615384616,
          "success@3": 0.5961538461538461,
          "ndcg@3": 0.5255825502051646,
          "recall@5": 0.5865384615384616,
          "success@5": 0.5961538461538461,
          "ndcg@5": 0.5255825502051646,
          "recall@10": 0.6442307692307693,
          "success@10": 0.6538461538461539,
          "ndcg@10": 0.5440107651750874,
          "mrr": 0.5258918218718139,
          "num_queries": 52,
          "num_candidates": 1006
        },
        "social_media/business": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.4659799295918451,
          "recall@5": 0.7142857142857143,
          "success@5": 0.7142857142857143,
          "ndcg@5": 0.5212446163396367,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.5663110273090266,
          "mrr": 0.47573637702503685,
          "num_queries": 7,
          "num_candidates": 1006
        },
        "social_media/sports": {
          "recall@1": 0.21794871794871795,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.2692307692307692,
          "success@3": 0.28205128205128205,
          "ndcg@3": 0.2532052999976506,
          "recall@5": 0.3717948717948718,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.29512988283395497,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.3493378780129108,
          "mrr": 0.3178967306959571,
          "num_queries": 39,
          "num_candidates": 1006
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.804418536224494,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.804418536224494,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.804418536224494,
          "mrr": 0.7860618700034758,
          "num_queries": 7,
          "num_candidates": 1006
        },
        "social_media/people": {
          "recall@1": 0.30357142857142855,
          "success@1": 0.30357142857142855,
          "ndcg@1": 0.30357142857142855,
          "recall@3": 0.39285714285714285,
          "success@3": 0.39285714285714285,
          "ndcg@3": 0.3482142857142857,
          "recall@5": 0.5178571428571429,
          "success@5": 0.5178571428571429,
          "ndcg@5": 0.4012662884941947,
          "recall@10": 0.5803571428571429,
          "success@10": 0.5892857142857143,
          "ndcg@10": 0.42213495786014604,
          "mrr": 0.3864624583073889,
          "num_queries": 56,
          "num_candidates": 1006
        },
        "social_media/entertainment": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.4888888888888889,
          "success@3": 0.4888888888888889,
          "ndcg@3": 0.422749311428574,
          "recall@5": 0.5222222222222223,
          "success@5": 0.5333333333333333,
          "ndcg@5": 0.43721422097984364,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.4628622941760417,
          "mrr": 0.43226651054627047,
          "num_queries": 45,
          "num_candidates": 1006
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.3065464876785729,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.3667655963056967,
          "recall@10": 0.65,
          "success@10": 0.65,
          "ndcg@10": 0.41480244081627865,
          "mrr": 0.3588466630439927,
          "num_queries": 20,
          "num_candidates": 1006
        },
        "social_media/technology": {
          "recall@1": 0.41379310344827586,
          "success@1": 0.41379310344827586,
          "ndcg@1": 0.41379310344827586,
          "recall@3": 0.5172413793103449,
          "success@3": 0.5172413793103449,
          "ndcg@3": 0.4700320604679813,
          "recall@5": 0.5862068965517241,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.4982227282372204,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.5194811721147966,
          "mrr": 0.4949209504153723,
          "num_queries": 29,
          "num_candidates": 1006
        },
        "social_media/social": {
          "recall@1": 0.20833333333333334,
          "success@1": 0.20833333333333334,
          "ndcg@1": 0.20833333333333334,
          "recall@3": 0.4166666666666667,
          "success@3": 0.4166666666666667,
          "ndcg@3": 0.3397770319940537,
          "recall@5": 0.4166666666666667,
          "success@5": 0.4166666666666667,
          "ndcg@5": 0.3397770319940537,
          "recall@10": 0.5416666666666666,
          "success@10": 0.5416666666666666,
          "ndcg@10": 0.37870773365004534,
          "mrr": 0.3461026893697785,
          "num_queries": 24,
          "num_candidates": 1006
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.6677536231884058,
          "num_queries": 5,
          "num_candidates": 1006
        },
        "social_media/health": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.55,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.5930676558073393,
          "recall@10": 0.7,
          "success@10": 0.7,
          "ndcg@10": 0.5930676558073393,
          "mrr": 0.5734848484848485,
          "num_queries": 10,
          "num_candidates": 1006
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1006
        },
        "social_media/science": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.4642857142857143,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.4642857142857143,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6428571428571429,
          "ndcg@10": 0.515172455301146,
          "mrr": 0.48867923205999914,
          "num_queries": 14,
          "num_candidates": 1006
        },
        "literature": {
          "recall@1": 0.3482142857142857,
          "success@1": 0.3630952380952381,
          "ndcg@1": 0.3630952380952381,
          "recall@3": 0.5565476190476191,
          "success@3": 0.5654761904761905,
          "ndcg@3": 0.4748951952792512,
          "recall@5": 0.625,
          "success@5": 0.625,
          "ndcg@5": 0.5029994186836417,
          "recall@10": 0.7797619047619048,
          "success@10": 0.7797619047619048,
          "ndcg@10": 0.553257800383677,
          "mrr": 0.4955495678845307,
          "num_queries": 168,
          "num_candidates": 1006
        },
        "social_media/economy": {
          "recall@1": 0.6666666666666666,
          "success@1": 0.6666666666666666,
          "ndcg@1": 0.6666666666666666,
          "recall@3": 0.8333333333333334,
          "success@3": 0.8333333333333334,
          "ndcg@3": 0.75,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.8144754678724236,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.8144754678724236,
          "mrr": 0.7555555555555555,
          "num_queries": 6,
          "num_candidates": 1006
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.011764705882352941,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/communications-media": {
          "recall@1": 0.6666666666666666,
          "success@1": 0.6666666666666666,
          "ndcg@1": 0.6666666666666666,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.8769765845238192,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.8769765845238192,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.8769765845238192,
          "mrr": 0.8333333333333334,
          "num_queries": 3,
          "num_candidates": 1006
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.01925252028522252,
          "num_queries": 3,
          "num_candidates": 1006
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0049261083743842365,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.38685280723454163,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.38685280723454163,
          "mrr": 0.2,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/indunk": {
          "recall@1": 0.3076923076923077,
          "success@1": 0.3076923076923077,
          "ndcg@1": 0.3076923076923077,
          "recall@3": 0.46153846153846156,
          "success@3": 0.46153846153846156,
          "ndcg@3": 0.39468690412088137,
          "recall@5": 0.5384615384615384,
          "success@5": 0.5384615384615384,
          "ndcg@5": 0.4244448123696923,
          "recall@10": 0.6923076923076923,
          "success@10": 0.6923076923076923,
          "ndcg@10": 0.4761118942076731,
          "mrr": 0.4117902749299876,
          "num_queries": 13,
          "num_candidates": 1006
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.041666666666666664,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.03125,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.5454545454545454,
          "success@3": 0.5454545454545454,
          "ndcg@3": 0.5,
          "recall@5": 0.6363636363636364,
          "success@5": 0.6363636363636364,
          "ndcg@5": 0.5391524143703085,
          "recall@10": 0.8181818181818182,
          "success@10": 0.8181818181818182,
          "ndcg@10": 0.5989012491677633,
          "mrr": 0.5421626984126985,
          "num_queries": 11,
          "num_candidates": 1006
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.044137099284158106,
          "num_queries": 4,
          "num_candidates": 1006
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3333333333333333,
          "mrr": 0.14285714285714285,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "ecommerce_reviews": {
          "recall@1": 0.15384615384615385,
          "success@1": 0.15384615384615385,
          "ndcg@1": 0.15384615384615385,
          "recall@3": 0.2564102564102564,
          "success@3": 0.2564102564102564,
          "ndcg@3": 0.21184255146520295,
          "recall@5": 0.38461538461538464,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.2648101229700559,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.3149340615087771,
          "mrr": 0.2679951301239766,
          "num_queries": 39,
          "num_candidates": 1006
        },
        "research_paper": {
          "recall@1": 0.8,
          "success@1": 0.8,
          "ndcg@1": 0.8,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.9261859507142916,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.9261859507142916,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.9261859507142916,
          "mrr": 0.9,
          "num_queries": 5,
          "num_candidates": 1006
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.14453241315894394,
          "mrr": 0.056329113924050635,
          "num_queries": 2,
          "num_candidates": 1006
        },
        "media_reviews/douban": {
          "recall@1": 0.09090909090909091,
          "success@1": 0.09090909090909091,
          "ndcg@1": 0.09090909090909091,
          "recall@3": 0.14545454545454545,
          "success@3": 0.14545454545454545,
          "ndcg@3": 0.12294290012987119,
          "recall@5": 0.18181818181818182,
          "success@5": 0.18181818181818182,
          "ndcg@5": 0.13701027493839998,
          "recall@10": 0.32727272727272727,
          "success@10": 0.34545454545454546,
          "ndcg@10": 0.18469063415147674,
          "mrr": 0.16554469458873106,
          "num_queries": 55,
          "num_candidates": 1006
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.8392857142857143,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.8392857142857143,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8520073995395723,
          "mrr": 0.8416889388143742,
          "num_queries": 28,
          "num_candidates": 1006
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.4036458333333333,
          "success@1": 0.4114583333333333,
          "ndcg@1": 0.4114583333333333,
          "recall@3": 0.5638020833333334,
          "success@3": 0.5703125,
          "ndcg@3": 0.4989676126291363,
          "recall@5": 0.625,
          "success@5": 0.6276041666666666,
          "ndcg@5": 0.5247471322406956,
          "recall@10": 0.7408854166666666,
          "success@10": 0.7447916666666666,
          "ndcg@10": 0.5631112391732769,
          "mrr": 0.5209082567598756,
          "num_queries": 384,
          "num_candidates": 1006
        },
        "medium": {
          "recall@1": 0.28515625,
          "success@1": 0.291015625,
          "ndcg@1": 0.291015625,
          "recall@3": 0.421875,
          "success@3": 0.427734375,
          "ndcg@3": 0.36508199795565865,
          "recall@5": 0.498046875,
          "success@5": 0.505859375,
          "ndcg@5": 0.3963990365810349,
          "recall@10": 0.6171875,
          "success@10": 0.62109375,
          "ndcg@10": 0.43554526641908253,
          "mrr": 0.396278694448451,
          "num_queries": 512,
          "num_candidates": 1006
        },
        "short": {
          "recall@1": 0.22916666666666666,
          "success@1": 0.2361111111111111,
          "ndcg@1": 0.2361111111111111,
          "recall@3": 0.3055555555555556,
          "success@3": 0.3055555555555556,
          "ndcg@3": 0.27265180213293694,
          "recall@5": 0.3611111111111111,
          "success@5": 0.3611111111111111,
          "ndcg@5": 0.2953609511692684,
          "recall@10": 0.4722222222222222,
          "success@10": 0.4861111111111111,
          "ndcg@10": 0.3333308209543351,
          "mrr": 0.30550564392066687,
          "num_queries": 72,
          "num_candidates": 1006
        },
        "extra_long": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.4077324383928644,
          "recall@5": 0.75,
          "success@5": 0.75,
          "ndcg@5": 0.5044456402014998,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5934974369785053,
          "mrr": 0.4666666666666667,
          "num_queries": 4,
          "num_candidates": 1006
        }
      }
    },
    "attribution": {
      "eer": 0.08928571428571429,
      "num_queries": 972,
      "positive_pairs": 1008,
      "negative_pairs": 48600,
      "num_candidates": 1006,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "by_language": {
        "ar": {
          "eer": 0.09090909090909091,
          "num_queries": 189,
          "positive_pairs": 198,
          "negative_pairs": 9450
        },
        "de": {
          "eer": 0.03907692307692308,
          "num_queries": 65,
          "positive_pairs": 65,
          "negative_pairs": 3250
        },
        "en": {
          "eer": 0.07432432432432433,
          "num_queries": 146,
          "positive_pairs": 148,
          "negative_pairs": 7300
        },
        "fr": {
          "eer": 0.04838709677419355,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.05861386138613861,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.025,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.01411764705882353,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.05173913043478261,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.06796992481203007,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06881889763779528,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08541516245487364,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.024210526315789474,
          "num_queries": 38,
          "positive_pairs": 44,
          "negative_pairs": 1900
        },
        "social_media/politics": {
          "eer": 0.09433962264150944,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.10285714285714286,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.07538461538461538,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.09285714285714286,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.07155555555555555,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.08,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.06896551724137931,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.08333333333333333,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.072,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.048,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.037142857142857144,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.05023809523809524,
          "num_queries": 168,
          "positive_pairs": 177,
          "negative_pairs": 8400
        },
        "social_media/economy": {
          "eer": 0.006666666666666667,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.0,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.3,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.2,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.23076923076923078,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.016363636363636365,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.125,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.05128205128205128,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.004,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/investing": {
          "eer": 0.04,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.08981818181818182,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.06428571428571428,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06733167082294264,
          "num_queries": 384,
          "positive_pairs": 401,
          "negative_pairs": 19200
        },
        "medium": {
          "eer": 0.0894921875,
          "num_queries": 512,
          "positive_pairs": 528,
          "negative_pairs": 25600
        },
        "short": {
          "eer": 0.10583333333333333,
          "num_queries": 72,
          "positive_pairs": 75,
          "negative_pairs": 3600
        },
        "extra_long": {
          "eer": 0.005,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        }
      }
    }
  }
}