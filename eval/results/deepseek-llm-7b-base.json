{
  "deepseek-llm-7b-base": {
    "hf_repo": "deepseek-ai/deepseek-llm-7b-base",
    "representation": {
      "recall@1": 0.2727272727272727,
      "success@1": 0.27964426877470355,
      "ndcg@1": 0.27964426877470355,
      "recall@3": 0.4006916996047431,
      "success@3": 0.40711462450592883,
      "ndcg@3": 0.34873350658494734,
      "recall@5": 0.4733201581027668,
      "success@5": 0.4792490118577075,
      "ndcg@5": 0.3787978467843955,
      "recall@10": 0.5721343873517787,
      "success@10": 0.5760869565217391,
      "ndcg@10": 0.4105873226433156,
      "mrr": 0.3787370072517444,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.14532019704433496,
          "success@1": 0.15270935960591134,
          "ndcg@1": 0.15270935960591134,
          "recall@3": 0.22167487684729065,
          "success@3": 0.2315270935960591,
          "ndcg@3": 0.1904169890042231,
          "recall@5": 0.2561576354679803,
          "success@5": 0.2660098522167488,
          "ndcg@5": 0.20488447959648973,
          "recall@10": 0.37192118226600984,
          "success@10": 0.3793103448275862,
          "ndcg@10": 0.24263968090852286,
          "mrr": 0.22975235943169361,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.44366197183098594,
          "success@1": 0.4507042253521127,
          "ndcg@1": 0.4507042253521127,
          "recall@3": 0.6267605633802817,
          "success@3": 0.6338028169014085,
          "ndcg@3": 0.5460252952200387,
          "recall@5": 0.6408450704225352,
          "success@5": 0.647887323943662,
          "ndcg@5": 0.552091162235157,
          "recall@10": 0.7746478873239436,
          "success@10": 0.7746478873239436,
          "ndcg@10": 0.5946335170569987,
          "mrr": 0.5548491307585162,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.2921686746987952,
          "success@1": 0.30120481927710846,
          "ndcg@1": 0.30120481927710846,
          "recall@3": 0.4307228915662651,
          "success@3": 0.43373493975903615,
          "ndcg@3": 0.37490936613459397,
          "recall@5": 0.5240963855421686,
          "success@5": 0.5240963855421686,
          "ndcg@5": 0.4135687049165308,
          "recall@10": 0.5843373493975904,
          "success@10": 0.5843373493975904,
          "ndcg@10": 0.4320286729255102,
          "mrr": 0.3982048193413953,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.3629032258064516,
          "success@1": 0.3709677419354839,
          "ndcg@1": 0.3709677419354839,
          "recall@3": 0.4838709677419355,
          "success@3": 0.4838709677419355,
          "ndcg@3": 0.4337546654953931,
          "recall@5": 0.6129032258064516,
          "success@5": 0.6129032258064516,
          "ndcg@5": 0.4857916608243105,
          "recall@10": 0.6935483870967742,
          "success@10": 0.6935483870967742,
          "ndcg@10": 0.5114637034659735,
          "mrr": 0.4703843614716335,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.3118811881188119,
          "success@1": 0.32673267326732675,
          "ndcg@1": 0.32673267326732675,
          "recall@3": 0.5,
          "success@3": 0.5148514851485149,
          "ndcg@3": 0.42818614738285904,
          "recall@5": 0.6237623762376238,
          "success@5": 0.6336633663366337,
          "ndcg@5": 0.4789318471868956,
          "recall@10": 0.6732673267326733,
          "success@10": 0.6732673267326733,
          "ndcg@10": 0.494854022486255,
          "mrr": 0.4532163605921804,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.35,
          "success@1": 0.35,
          "ndcg@1": 0.35,
          "recall@3": 0.525,
          "success@3": 0.525,
          "ndcg@3": 0.4440464876785729,
          "recall@5": 0.675,
          "success@5": 0.675,
          "ndcg@5": 0.5064567838476393,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.5476519763195729,
          "mrr": 0.4819338994338994,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.7352941176470589,
          "success@3": 0.7647058823529411,
          "ndcg@3": 0.5829748130306102,
          "recall@5": 0.9117647058823529,
          "success@5": 0.9411764705882353,
          "ndcg@5": 0.6512429554837645,
          "recall@10": 0.9117647058823529,
          "success@10": 0.9411764705882353,
          "ndcg@10": 0.6512429554837645,
          "mrr": 0.5798573975044563,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.2554347826086957,
          "success@1": 0.2608695652173913,
          "ndcg@1": 0.2608695652173913,
          "recall@3": 0.3695652173913043,
          "success@3": 0.3695652173913043,
          "ndcg@3": 0.32572998714912876,
          "recall@5": 0.41304347826086957,
          "success@5": 0.42391304347826086,
          "ndcg@5": 0.3444539148547801,
          "recall@10": 0.5271739130434783,
          "success@10": 0.532608695652174,
          "ndcg@10": 0.38176805340127695,
          "mrr": 0.35590582120189895,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.14285714285714285,
          "success@1": 0.14285714285714285,
          "ndcg@1": 0.14285714285714285,
          "recall@3": 0.2932330827067669,
          "success@3": 0.3007518796992481,
          "ndcg@3": 0.23486956329354094,
          "recall@5": 0.35714285714285715,
          "success@5": 0.3609022556390977,
          "ndcg@5": 0.26189935784751645,
          "recall@10": 0.4924812030075188,
          "success@10": 0.49624060150375937,
          "ndcg@10": 0.3048411961813022,
          "mrr": 0.2688579236227254,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.3937007874015748,
          "success@1": 0.4015748031496063,
          "ndcg@1": 0.4015748031496063,
          "recall@3": 0.452755905511811,
          "success@3": 0.4566929133858268,
          "ndcg@3": 0.4271187161128891,
          "recall@5": 0.515748031496063,
          "success@5": 0.5196850393700787,
          "ndcg@5": 0.4532127414047835,
          "recall@10": 0.6220472440944882,
          "success@10": 0.6299212598425197,
          "ndcg@10": 0.48809465107782946,
          "mrr": 0.46118724504902014,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.24729241877256317,
          "success@1": 0.2527075812274368,
          "ndcg@1": 0.2527075812274368,
          "recall@3": 0.40252707581227437,
          "success@3": 0.40794223826714804,
          "ndcg@3": 0.33916565950215766,
          "recall@5": 0.48014440433212996,
          "success@5": 0.48736462093862815,
          "ndcg@5": 0.3708706629269733,
          "recall@10": 0.5740072202166066,
          "success@10": 0.5776173285198556,
          "ndcg@10": 0.4009852687893338,
          "mrr": 0.3658011865029514,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.125,
          "success@1": 0.15384615384615385,
          "ndcg@1": 0.15384615384615385,
          "recall@3": 0.18269230769230768,
          "success@3": 0.21153846153846154,
          "ndcg@3": 0.16815532589109455,
          "recall@5": 0.23076923076923078,
          "success@5": 0.25,
          "ndcg@5": 0.18895527758110464,
          "recall@10": 0.2980769230769231,
          "success@10": 0.3269230769230769,
          "ndcg@10": 0.2132327108662511,
          "mrr": 0.22901327986635783,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.3269230769230769,
          "success@1": 0.3269230769230769,
          "ndcg@1": 0.3269230769230769,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.421015178090661,
          "recall@5": 0.5961538461538461,
          "success@5": 0.5961538461538461,
          "ndcg@5": 0.4607408567193007,
          "recall@10": 0.6538461538461539,
          "success@10": 0.6538461538461539,
          "ndcg@10": 0.4783855657214871,
          "mrr": 0.4344729871294906,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.42857142857142855,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.3758471076530654,
          "recall@5": 0.5714285714285714,
          "success@5": 0.5714285714285714,
          "ndcg@5": 0.43111179440085706,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.48199853541628884,
          "mrr": 0.41860102531578663,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.20512820512820512,
          "success@1": 0.20512820512820512,
          "ndcg@1": 0.20512820512820512,
          "recall@3": 0.21794871794871795,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.21504750787780877,
          "recall@5": 0.2948717948717949,
          "success@5": 0.3076923076923077,
          "ndcg@5": 0.24705278796450947,
          "recall@10": 0.48717948717948717,
          "success@10": 0.48717948717948717,
          "ndcg@10": 0.3098077916904738,
          "mrr": 0.2760596379824038,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.5714285714285714,
          "success@1": 0.5714285714285714,
          "ndcg@1": 0.5714285714285714,
          "recall@3": 0.7142857142857143,
          "success@3": 0.7142857142857143,
          "ndcg@3": 0.6615613933673511,
          "recall@5": 0.7142857142857143,
          "success@5": 0.7142857142857143,
          "ndcg@5": 0.6615613933673511,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.6615613933673511,
          "mrr": 0.6549037688561025,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.35714285714285715,
          "success@3": 0.35714285714285715,
          "ndcg@3": 0.29506641096938985,
          "recall@5": 0.38392857142857145,
          "success@5": 0.39285714285714285,
          "ndcg@5": 0.3069927372344378,
          "recall@10": 0.41964285714285715,
          "success@10": 0.42857142857142855,
          "ndcg@10": 0.3182593399767853,
          "mrr": 0.3024392926974176,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.35555555555555557,
          "success@1": 0.35555555555555557,
          "ndcg@1": 0.35555555555555557,
          "recall@3": 0.3888888888888889,
          "success@3": 0.4,
          "ndcg@3": 0.3752633957163231,
          "recall@5": 0.45555555555555555,
          "success@5": 0.4666666666666667,
          "ndcg@5": 0.40300130512479704,
          "recall@10": 0.5222222222222223,
          "success@10": 0.5333333333333333,
          "ndcg@10": 0.42435101379616685,
          "mrr": 0.4149612443353968,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.25,
          "success@3": 0.25,
          "ndcg@3": 0.25,
          "recall@5": 0.35,
          "success@5": 0.35,
          "ndcg@5": 0.2908764682653967,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.369909735169757,
          "mrr": 0.31947984677497604,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.4482758620689655,
          "success@1": 0.4482758620689655,
          "ndcg@1": 0.4482758620689655,
          "recall@3": 0.5517241379310345,
          "success@3": 0.5517241379310345,
          "ndcg@3": 0.5045148190886709,
          "recall@5": 0.5517241379310345,
          "success@5": 0.5517241379310345,
          "ndcg@5": 0.5045148190886709,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.5348306690300418,
          "mrr": 0.5133142488040623,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.20833333333333334,
          "success@1": 0.20833333333333334,
          "ndcg@1": 0.20833333333333334,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2762887397321441,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.2762887397321441,
          "recall@10": 0.4583333333333333,
          "success@10": 0.4583333333333333,
          "ndcg@10": 0.3170639625137792,
          "mrr": 0.293344203284593,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.6,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.6861353116146786,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.6861353116146786,
          "mrr": 0.6504889975550123,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.4,
          "success@1": 0.4,
          "ndcg@1": 0.4,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.4630929753571458,
          "recall@5": 0.6,
          "success@5": 0.6,
          "ndcg@5": 0.5017782560805999,
          "recall@10": 0.7,
          "success@10": 0.7,
          "ndcg@10": 0.5306847387123887,
          "mrr": 0.49240867992766735,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.8154648767857288,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.8154648767857288,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.8154648767857288,
          "mrr": 0.75,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.35714285714285715,
          "success@1": 0.35714285714285715,
          "ndcg@1": 0.35714285714285715,
          "recall@3": 0.35714285714285715,
          "success@3": 0.35714285714285715,
          "ndcg@3": 0.35714285714285715,
          "recall@5": 0.42857142857142855,
          "success@5": 0.42857142857142855,
          "ndcg@5": 0.3879054684338138,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6428571428571429,
          "ndcg@10": 0.4554984690830917,
          "mrr": 0.4178753125181696,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.2672413793103448,
          "success@1": 0.28160919540229884,
          "ndcg@1": 0.28160919540229884,
          "recall@3": 0.47126436781609193,
          "success@3": 0.4827586206896552,
          "ndcg@3": 0.3925297434926451,
          "recall@5": 0.5603448275862069,
          "success@5": 0.5689655172413793,
          "ndcg@5": 0.42966289927003987,
          "recall@10": 0.6896551724137931,
          "success@10": 0.6896551724137931,
          "ndcg@10": 0.4708988448051661,
          "mrr": 0.4208106903923237,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.5833333333333334,
          "recall@5": 0.6666666666666666,
          "success@5": 0.6666666666666666,
          "ndcg@5": 0.5833333333333334,
          "recall@10": 0.8333333333333334,
          "success@10": 0.8333333333333334,
          "ndcg@10": 0.642701197851337,
          "mrr": 0.5961538461538461,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.015384615384615385,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2103099178571525,
          "recall@5": 0.6666666666666666,
          "success@5": 0.6666666666666666,
          "ndcg@5": 0.3392608536019997,
          "recall@10": 0.6666666666666666,
          "success@10": 0.6666666666666666,
          "ndcg@10": 0.3392608536019997,
          "mrr": 0.23673469387755106,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.011164622246704068,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0041841004184100415,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.38685280723454163,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.38685280723454163,
          "mrr": 0.2,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.23076923076923078,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.38461538461538464,
          "success@3": 0.38461538461538464,
          "ndcg@3": 0.31776382719780444,
          "recall@5": 0.5384615384615384,
          "success@5": 0.5384615384615384,
          "ndcg@5": 0.38402175920909565,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.38402175920909565,
          "mrr": 0.3401177333736928,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.005649717514124294,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.06666666666666667,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.5,
          "success@3": 0.5454545454545454,
          "ndcg@3": 0.47673426784881057,
          "recall@5": 0.6363636363636364,
          "success@5": 0.6363636363636364,
          "ndcg@5": 0.5359088978312772,
          "recall@10": 0.8181818181818182,
          "success@10": 0.8181818181818182,
          "ndcg@10": 0.5985943996895822,
          "mrr": 0.5513496307613955,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.024576339835739838,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.02631578947368421,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.06666666666666667,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.10256410256410256,
          "success@1": 0.10256410256410256,
          "ndcg@1": 0.10256410256410256,
          "recall@3": 0.23076923076923078,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.17002383983516559,
          "recall@5": 0.38461538461538464,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.23403440000856704,
          "recall@10": 0.4358974358974359,
          "success@10": 0.4358974358974359,
          "ndcg@10": 0.24916503646964058,
          "mrr": 0.21290933209300114,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.7,
          "success@1": 0.72,
          "ndcg@1": 0.72,
          "recall@3": 0.84,
          "success@3": 0.84,
          "ndcg@3": 0.7925004019945024,
          "recall@5": 0.84,
          "success@5": 0.84,
          "ndcg@5": 0.7925004019945024,
          "recall@10": 0.88,
          "success@10": 0.88,
          "ndcg@10": 0.804062995047218,
          "mrr": 0.7876785243741764,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.1781035935540111,
          "mrr": 0.08865248226950354,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.07272727272727272,
          "success@1": 0.07272727272727272,
          "ndcg@1": 0.07272727272727272,
          "recall@3": 0.12727272727272726,
          "success@3": 0.12727272727272726,
          "ndcg@3": 0.1,
          "recall@5": 0.2,
          "success@5": 0.2,
          "ndcg@5": 0.12972834055665217,
          "recall@10": 0.37272727272727274,
          "success@10": 0.38181818181818183,
          "ndcg@10": 0.18652774302184785,
          "mrr": 0.14813978785911927,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.8392857142857143,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.8392857142857143,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.8392857142857143,
          "mrr": 0.8390242693814123,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.32558139534883723,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.5012919896640827,
          "success@3": 0.5064599483204134,
          "ndcg@3": 0.43043057292287995,
          "recall@5": 0.5658914728682171,
          "success@5": 0.5710594315245479,
          "ndcg@5": 0.4575282688893369,
          "recall@10": 0.665374677002584,
          "success@10": 0.6666666666666666,
          "ndcg@10": 0.48902785342429267,
          "mrr": 0.4508091969673323,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.24282982791587,
          "success@1": 0.24665391969407266,
          "ndcg@1": 0.24665391969407266,
          "recall@3": 0.35181644359464626,
          "success@3": 0.3575525812619503,
          "ndcg@3": 0.30601711176626273,
          "recall@5": 0.43690248565965584,
          "success@5": 0.4416826003824092,
          "ndcg@5": 0.3407949935714235,
          "recall@10": 0.5315487571701721,
          "success@10": 0.5353728489483748,
          "ndcg@10": 0.37144719736802456,
          "mrr": 0.34022454310014716,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.21333333333333335,
          "success@1": 0.22666666666666666,
          "ndcg@1": 0.22666666666666666,
          "recall@3": 0.26,
          "success@3": 0.26666666666666666,
          "ndcg@3": 0.2439296998540875,
          "recall@5": 0.3,
          "success@5": 0.30666666666666664,
          "ndcg@5": 0.2620979525406031,
          "recall@10": 0.3933333333333333,
          "success@10": 0.4,
          "ndcg@10": 0.2917771172274447,
          "mrr": 0.28188663011220705,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.25925925925925924,
          "success@1": 0.2962962962962963,
          "ndcg@1": 0.2962962962962963,
          "recall@3": 0.2962962962962963,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2962962962962963,
          "recall@5": 0.3333333333333333,
          "success@5": 0.37037037037037035,
          "ndcg@5": 0.3106241780457238,
          "recall@10": 0.5185185185185185,
          "success@10": 0.5555555555555556,
          "ndcg@10": 0.3744601194184881,
          "mrr": 0.360731807874665,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.09490118577075099,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.1031390134529148,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.05014084507042253,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.10469879518072289,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.053870967741935484,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.07476635514018691,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.0365,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.01411764705882353,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.06869565217391305,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.07458646616541353,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.07448818897637795,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08859205776173285,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.06230769230769231,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.0973076923076923,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.12,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.125,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.10526315789473684,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.11555555555555555,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.105,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.08344827586206896,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.11666666666666667,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.188,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.2,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.07142857142857142,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.06521739130434782,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.02666666666666667,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.08,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.10666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.21333333333333335,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.16,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.19538461538461538,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.24,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.038181818181818185,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.25,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.06051282051282051,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.07692307692307693,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.1,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.08145454545454546,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.034482758620689655,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.07673267326732673,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.09541108986615679,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.15653333333333333,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.05128205128205128,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}