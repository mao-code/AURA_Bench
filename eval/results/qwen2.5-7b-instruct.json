{
  "qwen2.5-7b-instruct": {
    "hf_repo": "Qwen/Qwen2.5-7B-Instruct",
    "representation": {
      "recall@1": 0.28606719367588934,
      "success@1": 0.29347826086956524,
      "ndcg@1": 0.29347826086956524,
      "recall@3": 0.4150197628458498,
      "success@3": 0.4209486166007905,
      "ndcg@3": 0.36265002686620584,
      "recall@5": 0.48122529644268774,
      "success@5": 0.4871541501976285,
      "ndcg@5": 0.3901864918949001,
      "recall@10": 0.5958498023715415,
      "success@10": 0.6007905138339921,
      "ndcg@10": 0.42710471426499125,
      "mrr": 0.39306969936446956,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.16502463054187191,
          "success@1": 0.1724137931034483,
          "ndcg@1": 0.1724137931034483,
          "recall@3": 0.26354679802955666,
          "success@3": 0.27586206896551724,
          "ndcg@3": 0.22560320900683944,
          "recall@5": 0.3226600985221675,
          "success@5": 0.33497536945812806,
          "ndcg@5": 0.250894377141992,
          "recall@10": 0.42610837438423643,
          "success@10": 0.43842364532019706,
          "ndcg@10": 0.28452582702491275,
          "mrr": 0.26628101178168917,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.45774647887323944,
          "success@1": 0.4647887323943662,
          "ndcg@1": 0.4647887323943662,
          "recall@3": 0.5704225352112676,
          "success@3": 0.5774647887323944,
          "ndcg@3": 0.5248985346566585,
          "recall@5": 0.6408450704225352,
          "success@5": 0.647887323943662,
          "ndcg@5": 0.5539933978776339,
          "recall@10": 0.7464788732394366,
          "success@10": 0.7464788732394366,
          "ndcg@10": 0.5887272284962465,
          "mrr": 0.5581932650415679,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.29819277108433734,
          "success@1": 0.3072289156626506,
          "ndcg@1": 0.3072289156626506,
          "recall@3": 0.4066265060240964,
          "success@3": 0.40963855421686746,
          "ndcg@3": 0.3603520873695325,
          "recall@5": 0.4578313253012048,
          "success@5": 0.4578313253012048,
          "ndcg@5": 0.3817444905312185,
          "recall@10": 0.572289156626506,
          "success@10": 0.572289156626506,
          "ndcg@10": 0.4177692521290917,
          "mrr": 0.38726094882152623,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.3951612903225806,
          "success@1": 0.4032258064516129,
          "ndcg@1": 0.4032258064516129,
          "recall@3": 0.532258064516129,
          "success@3": 0.532258064516129,
          "ndcg@3": 0.4761890163594489,
          "recall@5": 0.5967741935483871,
          "success@5": 0.5967741935483871,
          "ndcg@5": 0.501854096678433,
          "recall@10": 0.7096774193548387,
          "success@10": 0.7096774193548387,
          "ndcg@10": 0.5371958861890722,
          "mrr": 0.49567428478382375,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.3118811881188119,
          "success@1": 0.32673267326732675,
          "ndcg@1": 0.32673267326732675,
          "recall@3": 0.47029702970297027,
          "success@3": 0.4752475247524752,
          "ndcg@3": 0.4102405033248139,
          "recall@5": 0.5693069306930693,
          "success@5": 0.5742574257425742,
          "ndcg@5": 0.45071225408263244,
          "recall@10": 0.693069306930693,
          "success@10": 0.7029702970297029,
          "ndcg@10": 0.4909725771281646,
          "mrr": 0.4406202725354744,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.35,
          "success@1": 0.35,
          "ndcg@1": 0.35,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.4880929753571458,
          "recall@5": 0.65,
          "success@5": 0.65,
          "ndcg@5": 0.5085312094898441,
          "recall@10": 0.75,
          "success@10": 0.75,
          "ndcg@10": 0.5408829650784683,
          "mrr": 0.4906900379104327,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.4117647058823529,
          "success@1": 0.4117647058823529,
          "ndcg@1": 0.4117647058823529,
          "recall@3": 0.6176470588235294,
          "success@3": 0.6470588235294118,
          "ndcg@3": 0.5381595479045563,
          "recall@5": 0.8529411764705882,
          "success@5": 0.8823529411764706,
          "ndcg@5": 0.6369173409313046,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6836075855921139,
          "mrr": 0.5893790849673203,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.29891304347826086,
          "success@1": 0.30434782608695654,
          "ndcg@1": 0.30434782608695654,
          "recall@3": 0.3967391304347826,
          "success@3": 0.40217391304347827,
          "ndcg@3": 0.35474854572881837,
          "recall@5": 0.42391304347826086,
          "success@5": 0.42391304347826086,
          "ndcg@5": 0.36621297049052737,
          "recall@10": 0.6195652173913043,
          "success@10": 0.6195652173913043,
          "ndcg@10": 0.4304820569693755,
          "mrr": 0.3900269811766493,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.18045112781954886,
          "success@1": 0.18796992481203006,
          "ndcg@1": 0.18796992481203006,
          "recall@3": 0.34962406015037595,
          "success@3": 0.3533834586466165,
          "ndcg@3": 0.2809465002399553,
          "recall@5": 0.43609022556390975,
          "success@5": 0.44360902255639095,
          "ndcg@5": 0.3172338330070568,
          "recall@10": 0.5375939849624061,
          "success@10": 0.5413533834586466,
          "ndcg@10": 0.35022514027924473,
          "mrr": 0.31348416657470707,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.35826771653543305,
          "success@1": 0.36220472440944884,
          "ndcg@1": 0.36220472440944884,
          "recall@3": 0.4763779527559055,
          "success@3": 0.48031496062992124,
          "ndcg@3": 0.4290152864450854,
          "recall@5": 0.5354330708661418,
          "success@5": 0.5433070866141733,
          "ndcg@5": 0.45310729648360576,
          "recall@10": 0.6220472440944882,
          "success@10": 0.6299212598425197,
          "ndcg@10": 0.48020931640360076,
          "mrr": 0.45163051556383493,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.2833935018050541,
          "success@1": 0.2924187725631769,
          "ndcg@1": 0.2924187725631769,
          "recall@3": 0.4259927797833935,
          "success@3": 0.4332129963898917,
          "ndcg@3": 0.3683266056074046,
          "recall@5": 0.5072202166064982,
          "success@5": 0.5126353790613718,
          "ndcg@5": 0.40196439706167997,
          "recall@10": 0.6462093862815884,
          "success@10": 0.6462093862815884,
          "ndcg@10": 0.4466282908557299,
          "mrr": 0.40291234611875554,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.07692307692307693,
          "success@1": 0.09615384615384616,
          "ndcg@1": 0.09615384615384616,
          "recall@3": 0.18269230769230768,
          "success@3": 0.21153846153846154,
          "ndcg@3": 0.14806467032879042,
          "recall@5": 0.25961538461538464,
          "success@5": 0.28846153846153844,
          "ndcg@5": 0.1822250966466079,
          "recall@10": 0.33653846153846156,
          "success@10": 0.38461538461538464,
          "ndcg@10": 0.2058598940027094,
          "mrr": 0.20528005382520817,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.40384615384615385,
          "success@1": 0.40384615384615385,
          "ndcg@1": 0.40384615384615385,
          "recall@3": 0.5384615384615384,
          "success@3": 0.5384615384615384,
          "ndcg@3": 0.48122536565934293,
          "recall@5": 0.5769230769230769,
          "success@5": 0.5769230769230769,
          "ndcg@5": 0.4961043197837483,
          "recall@10": 0.6538461538461539,
          "success@10": 0.6538461538461539,
          "ndcg@10": 0.5206466614567747,
          "mrr": 0.4895071606782753,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.5187042505102083,
          "recall@5": 0.5714285714285714,
          "success@5": 0.5714285714285714,
          "ndcg@5": 0.5187042505102083,
          "recall@10": 0.5714285714285714,
          "success@10": 0.5714285714285714,
          "ndcg@10": 0.5187042505102083,
          "mrr": 0.5176664368344442,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.1794871794871795,
          "success@1": 0.1794871794871795,
          "ndcg@1": 0.1794871794871795,
          "recall@3": 0.32051282051282054,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.25816495137245243,
          "recall@5": 0.4230769230769231,
          "success@5": 0.4358974358974359,
          "ndcg@5": 0.3012132201277017,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.33798247077981924,
          "mrr": 0.2950629827921487,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.5714285714285714,
          "success@1": 0.5714285714285714,
          "ndcg@1": 0.5714285714285714,
          "recall@3": 0.7142857142857143,
          "success@3": 0.7142857142857143,
          "ndcg@3": 0.6428571428571429,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.6981218296049345,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.6981218296049345,
          "mrr": 0.6482897384305835,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.23214285714285715,
          "success@1": 0.23214285714285715,
          "ndcg@1": 0.23214285714285715,
          "recall@3": 0.30357142857142855,
          "success@3": 0.30357142857142855,
          "ndcg@3": 0.2725332054846949,
          "recall@5": 0.3392857142857143,
          "success@5": 0.3392857142857143,
          "ndcg@5": 0.28791451113017325,
          "recall@10": 0.4642857142857143,
          "success@10": 0.4642857142857143,
          "ndcg@10": 0.32772801415648684,
          "mrr": 0.3053920562584017,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.2222222222222222,
          "success@1": 0.2222222222222222,
          "ndcg@1": 0.2222222222222222,
          "recall@3": 0.3111111111111111,
          "success@3": 0.3111111111111111,
          "ndcg@3": 0.2753953169047639,
          "recall@5": 0.34444444444444444,
          "success@5": 0.35555555555555557,
          "ndcg@5": 0.2908340875857857,
          "recall@10": 0.4777777777777778,
          "success@10": 0.4888888888888889,
          "ndcg@10": 0.3356885268548326,
          "mrr": 0.3167011613739538,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.3,
          "success@3": 0.3,
          "ndcg@3": 0.275,
          "recall@5": 0.35,
          "success@5": 0.35,
          "ndcg@5": 0.29653382790366967,
          "recall@10": 0.55,
          "success@10": 0.55,
          "ndcg@10": 0.35937190233609645,
          "mrr": 0.31932283195791356,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.4827586206896552,
          "success@1": 0.4827586206896552,
          "ndcg@1": 0.4827586206896552,
          "recall@3": 0.5517241379310345,
          "success@3": 0.5517241379310345,
          "ndcg@3": 0.5262710174876868,
          "recall@5": 0.6551724137931034,
          "success@5": 0.6551724137931034,
          "ndcg@5": 0.5662902734085015,
          "recall@10": 0.6896551724137931,
          "success@10": 0.6896551724137931,
          "ndcg@10": 0.5785732798605021,
          "mrr": 0.5552602973894295,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.125,
          "success@1": 0.125,
          "ndcg@1": 0.125,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.24553288586309888,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.24553288586309888,
          "recall@10": 0.4166666666666667,
          "success@10": 0.4166666666666667,
          "ndcg@10": 0.272917768478599,
          "mrr": 0.24575417364257898,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.6675883256528418,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.5,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.5,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.5,
          "mrr": 0.5214239970555761,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.2857142857142857,
          "success@3": 0.2857142857142857,
          "ndcg@3": 0.25,
          "recall@5": 0.42857142857142855,
          "success@5": 0.42857142857142855,
          "ndcg@5": 0.3115252225819133,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.4048134649312752,
          "mrr": 0.3223676751402315,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.3132183908045977,
          "success@1": 0.3275862068965517,
          "ndcg@1": 0.3275862068965517,
          "recall@3": 0.5057471264367817,
          "success@3": 0.5114942528735632,
          "ndcg@3": 0.4302111239326793,
          "recall@5": 0.5804597701149425,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.46112880497152897,
          "recall@10": 0.7068965517241379,
          "success@10": 0.7126436781609196,
          "ndcg@10": 0.5027029445767454,
          "mrr": 0.45314812774276453,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.5,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.6362548942179891,
          "recall@10": 0.8333333333333334,
          "success@10": 0.8333333333333334,
          "ndcg@10": 0.6362548942179891,
          "mrr": 0.5888888888888889,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.013888888888888888,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2103099178571525,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.2103099178571525,
          "recall@10": 0.3333333333333333,
          "success@10": 0.3333333333333333,
          "ndcg@10": 0.2103099178571525,
          "mrr": 0.20124320124320125,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.010222781647942785,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.009259259259259259,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.31546487678572877,
          "mrr": 0.125,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.058823529411764705,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.3076923076923077,
          "success@1": 0.3076923076923077,
          "ndcg@1": 0.3076923076923077,
          "recall@3": 0.3076923076923077,
          "success@3": 0.3076923076923077,
          "ndcg@3": 0.3076923076923077,
          "recall@5": 0.46153846153846156,
          "success@5": 0.46153846153846156,
          "ndcg@5": 0.3705791819467642,
          "recall@10": 0.6153846153846154,
          "success@10": 0.6153846153846154,
          "ndcg@10": 0.41708146680088853,
          "mrr": 0.36221385871740924,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3562071871080222,
          "mrr": 0.16666666666666666,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.07142857142857142,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.012345679012345678,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.5454545454545454,
          "success@3": 0.5454545454545454,
          "ndcg@3": 0.49270188992256253,
          "recall@5": 0.5454545454545454,
          "success@5": 0.5454545454545454,
          "ndcg@5": 0.49270188992256253,
          "recall@10": 0.6363636363636364,
          "success@10": 0.6363636363636364,
          "ndcg@10": 0.5213805150849015,
          "mrr": 0.5110190726414635,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.25,
          "success@10": 0.25,
          "ndcg@10": 0.0752574989159953,
          "mrr": 0.04277380084399372,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.019230769230769232,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3010299956639812,
          "mrr": 0.1111111111111111,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.10256410256410256,
          "success@1": 0.10256410256410256,
          "ndcg@1": 0.10256410256410256,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2280202374542147,
          "recall@5": 0.41025641025641024,
          "success@5": 0.41025641025641024,
          "ndcg@5": 0.2589018316219705,
          "recall@10": 0.48717948717948717,
          "success@10": 0.48717948717948717,
          "ndcg@10": 0.2831683606054881,
          "mrr": 0.24135617113915522,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.74,
          "success@1": 0.76,
          "ndcg@1": 0.76,
          "recall@3": 0.74,
          "success@3": 0.76,
          "ndcg@3": 0.7445258877106185,
          "recall@5": 0.76,
          "success@5": 0.76,
          "ndcg@5": 0.7540137962213902,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7655763892741058,
          "mrr": 0.7751483486675304,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.25,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.25,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.25,
          "mrr": 0.17391304347826086,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.05454545454545454,
          "success@1": 0.05454545454545454,
          "ndcg@1": 0.05454545454545454,
          "recall@3": 0.15454545454545454,
          "success@3": 0.16363636363636364,
          "ndcg@3": 0.1127156883108564,
          "recall@5": 0.21818181818181817,
          "success@5": 0.23636363636363636,
          "ndcg@5": 0.13941478458567583,
          "recall@10": 0.32727272727272727,
          "success@10": 0.34545454545454546,
          "ndcg@10": 0.17469476134728268,
          "mrr": 0.15356517080962934,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8214285714285714,
          "success@5": 0.8214285714285714,
          "ndcg@5": 0.8214285714285714,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8436570771304007,
          "mrr": 0.8352119376945162,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.35012919896640826,
          "success@1": 0.35658914728682173,
          "ndcg@1": 0.35658914728682173,
          "recall@3": 0.49483204134366926,
          "success@3": 0.49870801033591733,
          "ndcg@3": 0.4382131210038261,
          "recall@5": 0.5607235142118863,
          "success@5": 0.5633074935400517,
          "ndcg@5": 0.46528864207498355,
          "recall@10": 0.6744186046511628,
          "success@10": 0.6795865633074936,
          "ndcg@10": 0.5022978357963339,
          "mrr": 0.46437202365788244,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.25239005736137665,
          "success@1": 0.25812619502868067,
          "ndcg@1": 0.25812619502868067,
          "recall@3": 0.3776290630975143,
          "success@3": 0.3824091778202677,
          "ndcg@3": 0.32443808512640215,
          "recall@5": 0.4521988527724665,
          "success@5": 0.4588910133843212,
          "ndcg@5": 0.3553992045117032,
          "recall@10": 0.5707456978967496,
          "success@10": 0.5736137667304015,
          "ndcg@10": 0.39344840788580493,
          "mrr": 0.3577438297514062,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.2,
          "success@1": 0.21333333333333335,
          "ndcg@1": 0.21333333333333335,
          "recall@3": 0.28,
          "success@3": 0.29333333333333333,
          "ndcg@3": 0.24801734780585719,
          "recall@5": 0.3,
          "success@5": 0.30666666666666664,
          "ndcg@5": 0.25692233808375975,
          "recall@10": 0.38,
          "success@10": 0.38666666666666666,
          "ndcg@10": 0.2816608434777683,
          "mrr": 0.2725201040055191,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.25925925925925924,
          "success@1": 0.2962962962962963,
          "ndcg@1": 0.2962962962962963,
          "recall@3": 0.37037037037037035,
          "success@3": 0.4074074074074074,
          "ndcg@3": 0.33818258346560953,
          "recall@5": 0.4074074074074074,
          "success@5": 0.4444444444444444,
          "ndcg@5": 0.3577431851376533,
          "recall@10": 0.5555555555555556,
          "success@10": 0.5925925925925926,
          "ndcg@10": 0.40528251103263246,
          "mrr": 0.39020488299422423,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.08105560791705937,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.08197044334975369,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.0428169014084507,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.08228915662650603,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.05,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06316831683168317,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.036,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.00823529411764706,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.05154639175257732,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.072992700729927,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06766917293233082,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.0768231046931408,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.047692307692307694,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.0876923076923077,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.14285714285714285,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.075,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.10035714285714285,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.072,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.1,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.05448275862068966,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.08,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.06,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.072,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.07142857142857142,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.059782608695652176,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.03333333333333333,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.1,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.02666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.10666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.1,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.15384615384615385,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.12,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.04363636363636364,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.23,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.055384615384615386,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.0264,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.04,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.08036363636363636,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.034482758620689655,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.07178217821782178,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.07606679035250463,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.1,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.06888888888888889,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}