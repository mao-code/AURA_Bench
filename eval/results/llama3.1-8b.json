{
  "llama3.1-8b": {
    "hf_repo": "meta-llama/Llama-3.1-8B",
    "representation": {
      "recall@1": 0.3310276679841897,
      "success@1": 0.33893280632411066,
      "ndcg@1": 0.33893280632411066,
      "recall@3": 0.46393280632411066,
      "success@3": 0.46936758893280633,
      "ndcg@3": 0.4089606722285876,
      "recall@5": 0.5281620553359684,
      "success@5": 0.5335968379446641,
      "ndcg@5": 0.43574209457366286,
      "recall@10": 0.6511857707509882,
      "success@10": 0.6561264822134387,
      "ndcg@10": 0.4761278768956903,
      "mrr": 0.4381756768281058,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.1896551724137931,
          "success@1": 0.2019704433497537,
          "ndcg@1": 0.2019704433497537,
          "recall@3": 0.25862068965517243,
          "success@3": 0.270935960591133,
          "ndcg@3": 0.23199700212607366,
          "recall@5": 0.32019704433497537,
          "success@5": 0.33497536945812806,
          "ndcg@5": 0.25780847359560594,
          "recall@10": 0.4630541871921182,
          "success@10": 0.47783251231527096,
          "ndcg@10": 0.30372504891041846,
          "mrr": 0.28429475349144423,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.5492957746478874,
          "success@1": 0.5492957746478874,
          "ndcg@1": 0.5492957746478874,
          "recall@3": 0.6690140845070423,
          "success@3": 0.676056338028169,
          "ndcg@3": 0.6203028390858004,
          "recall@5": 0.7676056338028169,
          "success@5": 0.7746478873239436,
          "ndcg@5": 0.6615294363370123,
          "recall@10": 0.8732394366197183,
          "success@10": 0.8732394366197183,
          "ndcg@10": 0.6961601359067734,
          "mrr": 0.6478527191623007,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.3463855421686747,
          "success@1": 0.35542168674698793,
          "ndcg@1": 0.35542168674698793,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.43748076858781404,
          "recall@5": 0.5542168674698795,
          "success@5": 0.5542168674698795,
          "ndcg@5": 0.46003870696217536,
          "recall@10": 0.6566265060240963,
          "success@10": 0.6566265060240963,
          "ndcg@10": 0.4946731280972975,
          "mrr": 0.4568041269760258,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.4435483870967742,
          "success@1": 0.45161290322580644,
          "ndcg@1": 0.45161290322580644,
          "recall@3": 0.5967741935483871,
          "success@3": 0.5967741935483871,
          "ndcg@3": 0.5284170888248857,
          "recall@5": 0.6451612903225806,
          "success@5": 0.6451612903225806,
          "ndcg@5": 0.5471357730459119,
          "recall@10": 0.8225806451612904,
          "success@10": 0.8225806451612904,
          "ndcg@10": 0.6035411556472571,
          "mrr": 0.5451080569009349,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.42574257425742573,
          "success@1": 0.44554455445544555,
          "ndcg@1": 0.44554455445544555,
          "recall@3": 0.5792079207920792,
          "success@3": 0.594059405940594,
          "ndcg@3": 0.5205970892127258,
          "recall@5": 0.6732673267326733,
          "success@5": 0.6732673267326733,
          "ndcg@5": 0.560118155235571,
          "recall@10": 0.7821782178217822,
          "success@10": 0.7821782178217822,
          "ndcg@10": 0.5967278111806252,
          "mrr": 0.5502426602646127,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.475,
          "success@1": 0.475,
          "ndcg@1": 0.475,
          "recall@3": 0.775,
          "success@3": 0.775,
          "ndcg@3": 0.6380929753571458,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.6488598893089806,
          "recall@10": 0.9,
          "success@10": 0.9,
          "ndcg@10": 0.6828020490000294,
          "mrr": 0.6180762235449736,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.5,
          "success@3": 0.5294117647058824,
          "ndcg@3": 0.43750019705612864,
          "recall@5": 0.7352941176470589,
          "success@5": 0.7647058823529411,
          "ndcg@5": 0.53883585777928,
          "recall@10": 0.9411764705882353,
          "success@10": 0.9411764705882353,
          "ndcg@10": 0.6121217900209336,
          "mrr": 0.5151515151515151,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.29891304347826086,
          "success@1": 0.30434782608695654,
          "ndcg@1": 0.30434782608695654,
          "recall@3": 0.42391304347826086,
          "success@3": 0.42391304347826086,
          "ndcg@3": 0.37037358214136384,
          "recall@5": 0.47282608695652173,
          "success@5": 0.4782608695652174,
          "ndcg@5": 0.39072419565642,
          "recall@10": 0.5978260869565217,
          "success@10": 0.6086956521739131,
          "ndcg@10": 0.4333734232559441,
          "mrr": 0.39917056296139036,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21804511278195488,
          "ndcg@1": 0.21804511278195488,
          "recall@3": 0.40225563909774437,
          "success@3": 0.40601503759398494,
          "ndcg@3": 0.3229034867877133,
          "recall@5": 0.48872180451127817,
          "success@5": 0.48872180451127817,
          "ndcg@5": 0.3578728120107892,
          "recall@10": 0.6165413533834586,
          "success@10": 0.6165413533834586,
          "ndcg@10": 0.398898118014447,
          "mrr": 0.3498824949342638,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.38188976377952755,
          "success@1": 0.3858267716535433,
          "ndcg@1": 0.3858267716535433,
          "recall@3": 0.4645669291338583,
          "success@3": 0.4645669291338583,
          "ndcg@3": 0.431382508042746,
          "recall@5": 0.4881889763779528,
          "success@5": 0.49606299212598426,
          "ndcg@5": 0.442111791125334,
          "recall@10": 0.5905511811023622,
          "success@10": 0.5984251968503937,
          "ndcg@10": 0.47489055095191385,
          "mrr": 0.455000199370661,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.33935018050541516,
          "success@1": 0.34657039711191334,
          "ndcg@1": 0.34657039711191334,
          "recall@3": 0.4747292418772563,
          "success@3": 0.48014440433212996,
          "ndcg@3": 0.41761153278619695,
          "recall@5": 0.575812274368231,
          "success@5": 0.5812274368231047,
          "ndcg@5": 0.45950195839362384,
          "recall@10": 0.6841155234657039,
          "success@10": 0.6859205776173285,
          "ndcg@10": 0.4954514414250039,
          "mrr": 0.45193295097419955,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.08653846153846154,
          "success@1": 0.11538461538461539,
          "ndcg@1": 0.11538461538461539,
          "recall@3": 0.22115384615384615,
          "success@3": 0.25,
          "ndcg@3": 0.17010342368800396,
          "recall@5": 0.27884615384615385,
          "success@5": 0.3076923076923077,
          "ndcg@5": 0.19714838174480917,
          "recall@10": 0.41346153846153844,
          "success@10": 0.46153846153846156,
          "ndcg@10": 0.2416894384913893,
          "mrr": 0.2294204617471048,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.4230769230769231,
          "success@1": 0.4230769230769231,
          "ndcg@1": 0.4230769230769231,
          "recall@3": 0.5576923076923077,
          "success@3": 0.5576923076923077,
          "ndcg@3": 0.5004561348901121,
          "recall@5": 0.5865384615384616,
          "success@5": 0.5961538461538461,
          "ndcg@5": 0.5129738450787108,
          "recall@10": 0.625,
          "success@10": 0.6346153846153846,
          "ndcg@10": 0.5249430404566189,
          "mrr": 0.5075688495574885,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.5187042505102083,
          "recall@5": 0.7142857142857143,
          "success@5": 0.7142857142857143,
          "ndcg@5": 0.5739689372579999,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.6215879848770475,
          "mrr": 0.5496319075575437,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.21794871794871795,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.2948717948717949,
          "success@3": 0.3076923076923077,
          "ndcg@3": 0.26602581281816345,
          "recall@5": 0.32051282051282054,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.2759451155677671,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.346112037917267,
          "mrr": 0.3146051184457325,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.804418536224494,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.804418536224494,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.804418536224494,
          "mrr": 0.7860017246335154,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.32142857142857145,
          "success@1": 0.32142857142857145,
          "ndcg@1": 0.32142857142857145,
          "recall@3": 0.4107142857142857,
          "success@3": 0.4107142857142857,
          "ndcg@3": 0.3684094598852046,
          "recall@5": 0.4642857142857143,
          "success@5": 0.4642857142857143,
          "ndcg@5": 0.3906988513741569,
          "recall@10": 0.5803571428571429,
          "success@10": 0.5892857142857143,
          "ndcg@10": 0.42867943464075087,
          "mrr": 0.3977358250623458,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.4888888888888889,
          "success@3": 0.4888888888888889,
          "ndcg@3": 0.422749311428574,
          "recall@5": 0.5111111111111111,
          "success@5": 0.5111111111111111,
          "ndcg@5": 0.43134604047823044,
          "recall@10": 0.6444444444444445,
          "success@10": 0.6444444444444445,
          "ndcg@10": 0.4753579073488205,
          "mrr": 0.43260360867696274,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.3065464876785729,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.3667655963056967,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.40238631501649885,
          "mrr": 0.3592847667400399,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.41379310344827586,
          "success@1": 0.41379310344827586,
          "ndcg@1": 0.41379310344827586,
          "recall@3": 0.5172413793103449,
          "success@3": 0.5172413793103449,
          "ndcg@3": 0.4700320604679813,
          "recall@5": 0.5517241379310345,
          "success@5": 0.5517241379310345,
          "ndcg@5": 0.4848829762636156,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.5195383347886874,
          "mrr": 0.49374348878645874,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.16666666666666666,
          "success@1": 0.16666666666666666,
          "ndcg@1": 0.16666666666666666,
          "recall@3": 0.4166666666666667,
          "success@3": 0.4166666666666667,
          "ndcg@3": 0.3134882922619096,
          "recall@5": 0.4166666666666667,
          "success@5": 0.4166666666666667,
          "ndcg@5": 0.3134882922619096,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.34037462615465586,
          "mrr": 0.310984944702904,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.6676767676767676,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.6,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.6430676558073393,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.671974138439128,
          "mrr": 0.6421095571095571,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.402209268112247,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.402209268112247,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6428571428571429,
          "ndcg@10": 0.4514621624294866,
          "mrr": 0.4040462140873774,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.382183908045977,
          "success@1": 0.39655172413793105,
          "ndcg@1": 0.39655172413793105,
          "recall@3": 0.5459770114942529,
          "success@3": 0.5574712643678161,
          "ndcg@3": 0.48209004076275863,
          "recall@5": 0.6293103448275862,
          "success@5": 0.632183908045977,
          "ndcg@5": 0.5161468896390811,
          "recall@10": 0.7931034482758621,
          "success@10": 0.7931034482758621,
          "ndcg@10": 0.5690509750679436,
          "mrr": 0.5124768609796082,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.6051549589285763,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.6769343852741417,
          "recall@10": 0.8333333333333334,
          "success@10": 0.8333333333333334,
          "ndcg@10": 0.6769343852741417,
          "mrr": 0.6361111111111112,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.011764705882352941,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.7103099178571526,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.7103099178571526,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.7103099178571526,
          "mrr": 0.611111111111111,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.017844599844599848,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0040650406504065045,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3562071871080222,
          "mrr": 0.16666666666666666,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.08333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.3076923076923077,
          "success@1": 0.3076923076923077,
          "ndcg@1": 0.3076923076923077,
          "recall@3": 0.38461538461538464,
          "success@3": 0.38461538461538464,
          "ndcg@3": 0.35622536565934293,
          "recall@5": 0.5384615384615384,
          "success@5": 0.5384615384615384,
          "ndcg@5": 0.42248329767063414,
          "recall@10": 0.6923076923076923,
          "success@10": 0.6923076923076923,
          "ndcg@10": 0.47239085229517735,
          "mrr": 0.40740742930565904,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.03225806451612903,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.02702702702702703,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.6363636363636364,
          "success@3": 0.6363636363636364,
          "ndcg@3": 0.5454545454545454,
          "recall@5": 0.7272727272727273,
          "success@5": 0.7272727272727273,
          "ndcg@5": 0.5806229824758674,
          "recall@10": 0.9090909090909091,
          "success@10": 0.9090909090909091,
          "ndcg@10": 0.6382923760210779,
          "mrr": 0.5596681096681096,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.04561441702951136,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.1282051282051282,
          "success@1": 0.1282051282051282,
          "ndcg@1": 0.1282051282051282,
          "recall@3": 0.28205128205128205,
          "success@3": 0.28205128205128205,
          "ndcg@3": 0.21184255146520295,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.23392852880230003,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.3045371953432704,
          "mrr": 0.25353980486001926,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.74,
          "success@1": 0.76,
          "ndcg@1": 0.76,
          "recall@3": 0.84,
          "success@3": 0.84,
          "ndcg@3": 0.8020260217087858,
          "recall@5": 0.84,
          "success@5": 0.84,
          "ndcg@5": 0.8020260217087858,
          "recall@10": 0.88,
          "success@10": 0.88,
          "ndcg@10": 0.8153593550421192,
          "mrr": 0.8050576441102757,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.16666666666666666,
          "mrr": 0.07818532818532818,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.07272727272727272,
          "success@1": 0.07272727272727272,
          "ndcg@1": 0.07272727272727272,
          "recall@3": 0.14545454545454545,
          "success@3": 0.14545454545454545,
          "ndcg@3": 0.1138519910389621,
          "recall@5": 0.16363636363636364,
          "success@5": 0.18181818181818182,
          "ndcg@5": 0.1229659153179055,
          "recall@10": 0.3090909090909091,
          "success@10": 0.32727272727272727,
          "ndcg@10": 0.16917322855970265,
          "mrr": 0.1530229732761935,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8214285714285714,
          "success@5": 0.8214285714285714,
          "ndcg@5": 0.8214285714285714,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8445999360756807,
          "mrr": 0.8344214713857571,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.3953488372093023,
          "success@1": 0.40310077519379844,
          "ndcg@1": 0.40310077519379844,
          "recall@3": 0.5581395348837209,
          "success@3": 0.5633074935400517,
          "ndcg@3": 0.4893092992697661,
          "recall@5": 0.6227390180878553,
          "success@5": 0.6253229974160207,
          "ndcg@5": 0.5161364378044738,
          "recall@10": 0.7364341085271318,
          "success@10": 0.7390180878552972,
          "ndcg@10": 0.5532734832252149,
          "mrr": 0.5101950052699931,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.3011472275334608,
          "success@1": 0.3078393881453155,
          "ndcg@1": 0.3078393881453155,
          "recall@3": 0.4216061185468451,
          "success@3": 0.42638623326959846,
          "ndcg@3": 0.3725462786662437,
          "recall@5": 0.48661567877629064,
          "success@5": 0.4933078393881453,
          "ndcg@5": 0.3995574168430114,
          "recall@10": 0.6137667304015296,
          "success@10": 0.6175908221797323,
          "ndcg@10": 0.44131768970131985,
          "mrr": 0.4056433964237997,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.24,
          "success@1": 0.25333333333333335,
          "ndcg@1": 0.25333333333333335,
          "recall@3": 0.32,
          "success@3": 0.32,
          "ndcg@3": 0.2873420072362619,
          "recall@5": 0.38,
          "success@5": 0.38666666666666666,
          "ndcg@5": 0.31324801528995944,
          "recall@10": 0.5066666666666667,
          "success@10": 0.52,
          "ndcg@10": 0.35473363258182633,
          "mrr": 0.32408784084348974,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.24074074074074073,
          "success@1": 0.25925925925925924,
          "ndcg@1": 0.25925925925925924,
          "recall@3": 0.3333333333333333,
          "success@3": 0.37037037037037035,
          "ndcg@3": 0.3004869330653874,
          "recall@5": 0.3888888888888889,
          "success@5": 0.4074074074074074,
          "ndcg@5": 0.32459511565083676,
          "recall@10": 0.5555555555555556,
          "success@10": 0.5925925925925926,
          "ndcg@10": 0.38186663899456225,
          "mrr": 0.3529716117647298,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.08857707509881423,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.08295566502463055,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.038873239436619716,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.0663855421686747,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.03967741935483871,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06415841584158416,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.025,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.010588235294117647,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.04521739130434783,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.058394160583941604,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06766917293233082,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08584837545126353,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.038461538461538464,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.09192307692307693,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.10571428571428572,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.075,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.09,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.06521739130434782,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.09,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.0703448275862069,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.0725,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.064,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.054,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.037142857142857144,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.04891304347826087,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.02,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.12,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.006666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.23333333333333334,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.22,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.22923076923076924,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.08,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.016363636363636365,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.145,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.05128205128205128,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.0208,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.04,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.08254545454545455,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.045714285714285714,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06683168316831684,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.08684512428298279,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.10613333333333333,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.10256410256410256,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}