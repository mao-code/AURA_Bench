{
  "llama3.1-8b": {
    "hf_repo": "meta-llama/Llama-3.1-8B",
    "representation": {
      "recall@1": 0.3281893004115226,
      "success@1": 0.33539094650205764,
      "ndcg@1": 0.33539094650205764,
      "recall@3": 0.4655349794238683,
      "success@3": 0.4711934156378601,
      "ndcg@3": 0.40873520393433865,
      "recall@5": 0.529320987654321,
      "success@5": 0.5349794238683128,
      "ndcg@5": 0.43528960169397823,
      "recall@10": 0.6553497942386831,
      "success@10": 0.6594650205761317,
      "ndcg@10": 0.4766956389609395,
      "mrr": 0.43744746091195036,
      "num_queries": 972,
      "num_candidates": 1006,
      "by_language": {
        "ar": {
          "recall@1": 0.21164021164021163,
          "success@1": 0.2222222222222222,
          "ndcg@1": 0.2222222222222222,
          "recall@3": 0.291005291005291,
          "success@3": 0.30687830687830686,
          "ndcg@3": 0.2616683212190142,
          "recall@5": 0.34656084656084657,
          "success@5": 0.36507936507936506,
          "ndcg@5": 0.2846030128841097,
          "recall@10": 0.4973544973544973,
          "success@10": 0.5079365079365079,
          "ndcg@10": 0.3331268807541322,
          "mrr": 0.3117111145594294,
          "num_queries": 189,
          "num_candidates": 1006
        },
        "de": {
          "recall@1": 0.5538461538461539,
          "success@1": 0.5538461538461539,
          "ndcg@1": 0.5538461538461539,
          "recall@3": 0.676923076923077,
          "success@3": 0.676923076923077,
          "ndcg@3": 0.6254561348901121,
          "recall@5": 0.7846153846153846,
          "success@5": 0.7846153846153846,
          "ndcg@5": 0.6704882641952821,
          "recall@10": 0.8769230769230769,
          "success@10": 0.8769230769230769,
          "ndcg@10": 0.7006762040529063,
          "mrr": 0.6519338712425463,
          "num_queries": 65,
          "num_candidates": 1006
        },
        "en": {
          "recall@1": 0.2945205479452055,
          "success@1": 0.3013698630136986,
          "ndcg@1": 0.3013698630136986,
          "recall@3": 0.4589041095890411,
          "success@3": 0.4589041095890411,
          "ndcg@3": 0.39089833590998285,
          "recall@5": 0.5136986301369864,
          "success@5": 0.5136986301369864,
          "ndcg@5": 0.4138967260668968,
          "recall@10": 0.6301369863013698,
          "success@10": 0.6301369863013698,
          "ndcg@10": 0.453432258684739,
          "mrr": 0.4110602828736194,
          "num_queries": 146,
          "num_candidates": 1006
        },
        "fr": {
          "recall@1": 0.4435483870967742,
          "success@1": 0.45161290322580644,
          "ndcg@1": 0.45161290322580644,
          "recall@3": 0.5967741935483871,
          "success@3": 0.5967741935483871,
          "ndcg@3": 0.5284170888248857,
          "recall@5": 0.6451612903225806,
          "success@5": 0.6451612903225806,
          "ndcg@5": 0.5471357730459119,
          "recall@10": 0.8225806451612904,
          "success@10": 0.8225806451612904,
          "ndcg@10": 0.6035411556472571,
          "mrr": 0.5451080569009349,
          "num_queries": 62,
          "num_candidates": 1006
        },
        "es": {
          "recall@1": 0.42574257425742573,
          "success@1": 0.44554455445544555,
          "ndcg@1": 0.44554455445544555,
          "recall@3": 0.5792079207920792,
          "success@3": 0.594059405940594,
          "ndcg@3": 0.5205970892127258,
          "recall@5": 0.6732673267326733,
          "success@5": 0.6732673267326733,
          "ndcg@5": 0.560118155235571,
          "recall@10": 0.7821782178217822,
          "success@10": 0.7821782178217822,
          "ndcg@10": 0.5967278111806252,
          "mrr": 0.5502426602646127,
          "num_queries": 101,
          "num_candidates": 1006
        },
        "hi": {
          "recall@1": 0.475,
          "success@1": 0.475,
          "ndcg@1": 0.475,
          "recall@3": 0.775,
          "success@3": 0.775,
          "ndcg@3": 0.6380929753571458,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.6488598893089806,
          "recall@10": 0.9,
          "success@10": 0.9,
          "ndcg@10": 0.6828020490000294,
          "mrr": 0.6180762235449736,
          "num_queries": 40,
          "num_candidates": 1006
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.5,
          "success@3": 0.5294117647058824,
          "ndcg@3": 0.43750019705612864,
          "recall@5": 0.7352941176470589,
          "success@5": 0.7647058823529411,
          "ndcg@5": 0.53883585777928,
          "recall@10": 0.9411764705882353,
          "success@10": 0.9411764705882353,
          "ndcg@10": 0.6121217900209336,
          "mrr": 0.5151515151515151,
          "num_queries": 17,
          "num_candidates": 1006
        },
        "ko": {
          "recall@1": 0.29891304347826086,
          "success@1": 0.30434782608695654,
          "ndcg@1": 0.30434782608695654,
          "recall@3": 0.42391304347826086,
          "success@3": 0.42391304347826086,
          "ndcg@3": 0.37037358214136384,
          "recall@5": 0.47282608695652173,
          "success@5": 0.4782608695652174,
          "ndcg@5": 0.39072419565642,
          "recall@10": 0.5978260869565217,
          "success@10": 0.6086956521739131,
          "ndcg@10": 0.4333734232559441,
          "mrr": 0.39917056296139036,
          "num_queries": 92,
          "num_candidates": 1006
        },
        "ru": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21804511278195488,
          "ndcg@1": 0.21804511278195488,
          "recall@3": 0.40225563909774437,
          "success@3": 0.40601503759398494,
          "ndcg@3": 0.3229034867877133,
          "recall@5": 0.48872180451127817,
          "success@5": 0.48872180451127817,
          "ndcg@5": 0.3578728120107892,
          "recall@10": 0.6165413533834586,
          "success@10": 0.6165413533834586,
          "ndcg@10": 0.398898118014447,
          "mrr": 0.3498824949342638,
          "num_queries": 133,
          "num_candidates": 1006
        },
        "zh": {
          "recall@1": 0.38188976377952755,
          "success@1": 0.3858267716535433,
          "ndcg@1": 0.3858267716535433,
          "recall@3": 0.4645669291338583,
          "success@3": 0.4645669291338583,
          "ndcg@3": 0.431382508042746,
          "recall@5": 0.4881889763779528,
          "success@5": 0.49606299212598426,
          "ndcg@5": 0.442111791125334,
          "recall@10": 0.5905511811023622,
          "success@10": 0.5984251968503937,
          "ndcg@10": 0.47489055095191385,
          "mrr": 0.455001038517379,
          "num_queries": 127,
          "num_candidates": 1006
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.33935018050541516,
          "success@1": 0.34657039711191334,
          "ndcg@1": 0.34657039711191334,
          "recall@3": 0.4747292418772563,
          "success@3": 0.48014440433212996,
          "ndcg@3": 0.41761153278619695,
          "recall@5": 0.575812274368231,
          "success@5": 0.5812274368231047,
          "ndcg@5": 0.45950195839362384,
          "recall@10": 0.6841155234657039,
          "success@10": 0.6859205776173285,
          "ndcg@10": 0.4954514414250039,
          "mrr": 0.45196775336981704,
          "num_queries": 277,
          "num_candidates": 1006
        },
        "poetry": {
          "recall@1": 0.15789473684210525,
          "success@1": 0.18421052631578946,
          "ndcg@1": 0.18421052631578946,
          "recall@3": 0.3684210526315789,
          "success@3": 0.42105263157894735,
          "ndcg@3": 0.2948762976467614,
          "recall@5": 0.39473684210526316,
          "success@5": 0.4473684210526316,
          "ndcg@5": 0.30806750383996895,
          "recall@10": 0.5657894736842105,
          "success@10": 0.6052631578947368,
          "ndcg@10": 0.36390467969086404,
          "mrr": 0.34248302704564315,
          "num_queries": 38,
          "num_candidates": 1006
        },
        "social_media/politics": {
          "recall@1": 0.4230769230769231,
          "success@1": 0.4230769230769231,
          "ndcg@1": 0.4230769230769231,
          "recall@3": 0.5576923076923077,
          "success@3": 0.5576923076923077,
          "ndcg@3": 0.5004561348901121,
          "recall@5": 0.5865384615384616,
          "success@5": 0.5961538461538461,
          "ndcg@5": 0.5129738450787108,
          "recall@10": 0.625,
          "success@10": 0.6346153846153846,
          "ndcg@10": 0.5249430404566189,
          "mrr": 0.5079771271304019,
          "num_queries": 52,
          "num_candidates": 1006
        },
        "social_media/business": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.5187042505102083,
          "recall@5": 0.7142857142857143,
          "success@5": 0.7142857142857143,
          "ndcg@5": 0.5739689372579999,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.6215879848770475,
          "mrr": 0.5497159688617715,
          "num_queries": 7,
          "num_candidates": 1006
        },
        "social_media/sports": {
          "recall@1": 0.21794871794871795,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.2948717948717949,
          "success@3": 0.3076923076923077,
          "ndcg@3": 0.26602581281816345,
          "recall@5": 0.32051282051282054,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.2759451155677671,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.346112037917267,
          "mrr": 0.31486450713705283,
          "num_queries": 39,
          "num_candidates": 1006
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.804418536224494,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.804418536224494,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.804418536224494,
          "mrr": 0.7860169491525424,
          "num_queries": 7,
          "num_candidates": 1006
        },
        "social_media/people": {
          "recall@1": 0.32142857142857145,
          "success@1": 0.32142857142857145,
          "ndcg@1": 0.32142857142857145,
          "recall@3": 0.4107142857142857,
          "success@3": 0.4107142857142857,
          "ndcg@3": 0.3684094598852046,
          "recall@5": 0.4642857142857143,
          "success@5": 0.4642857142857143,
          "ndcg@5": 0.3906988513741569,
          "recall@10": 0.5803571428571429,
          "success@10": 0.5892857142857143,
          "ndcg@10": 0.42966474163082297,
          "mrr": 0.3990797385092723,
          "num_queries": 56,
          "num_candidates": 1006
        },
        "social_media/entertainment": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.4888888888888889,
          "success@3": 0.4888888888888889,
          "ndcg@3": 0.422749311428574,
          "recall@5": 0.5111111111111111,
          "success@5": 0.5111111111111111,
          "ndcg@5": 0.43134604047823044,
          "recall@10": 0.6444444444444445,
          "success@10": 0.6444444444444445,
          "ndcg@10": 0.47562380000095583,
          "mrr": 0.43286680919877474,
          "num_queries": 45,
          "num_candidates": 1006
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.3065464876785729,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.3667655963056967,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.40238631501649885,
          "mrr": 0.35982472770196555,
          "num_queries": 20,
          "num_candidates": 1006
        },
        "social_media/technology": {
          "recall@1": 0.41379310344827586,
          "success@1": 0.41379310344827586,
          "ndcg@1": 0.41379310344827586,
          "recall@3": 0.5172413793103449,
          "success@3": 0.5172413793103449,
          "ndcg@3": 0.4700320604679813,
          "recall@5": 0.5517241379310345,
          "success@5": 0.5517241379310345,
          "ndcg@5": 0.4848829762636156,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.5195383347886874,
          "mrr": 0.4938009600508265,
          "num_queries": 29,
          "num_candidates": 1006
        },
        "social_media/social": {
          "recall@1": 0.16666666666666666,
          "success@1": 0.16666666666666666,
          "ndcg@1": 0.16666666666666666,
          "recall@3": 0.4166666666666667,
          "success@3": 0.4166666666666667,
          "ndcg@3": 0.3134882922619096,
          "recall@5": 0.4166666666666667,
          "success@5": 0.4166666666666667,
          "ndcg@5": 0.3134882922619096,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.34037462615465586,
          "mrr": 0.3111057263045162,
          "num_queries": 24,
          "num_candidates": 1006
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.667816091954023,
          "num_queries": 5,
          "num_candidates": 1006
        },
        "social_media/health": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.6,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.6430676558073393,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.671974138439128,
          "mrr": 0.6425641025641026,
          "num_queries": 10,
          "num_candidates": 1006
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1006
        },
        "social_media/science": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.402209268112247,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.402209268112247,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6428571428571429,
          "ndcg@10": 0.4514621624294866,
          "mrr": 0.4040462140873774,
          "num_queries": 14,
          "num_candidates": 1006
        },
        "literature": {
          "recall@1": 0.37797619047619047,
          "success@1": 0.39285714285714285,
          "ndcg@1": 0.39285714285714285,
          "recall@3": 0.5446428571428571,
          "success@3": 0.5535714285714286,
          "ndcg@3": 0.4791477040802706,
          "recall@5": 0.6309523809523809,
          "success@5": 0.6309523809523809,
          "ndcg@5": 0.5144208689878902,
          "recall@10": 0.7916666666666666,
          "success@10": 0.7916666666666666,
          "ndcg@10": 0.5661224965601518,
          "mrr": 0.5090725501603304,
          "num_queries": 168,
          "num_candidates": 1006
        },
        "social_media/economy": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.6051549589285763,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.6769343852741417,
          "recall@10": 0.8333333333333334,
          "success@10": 0.8333333333333334,
          "ndcg@10": 0.6769343852741417,
          "mrr": 0.6361111111111112,
          "num_queries": 6,
          "num_candidates": 1006
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.012195121951219513,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/communications-media": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.7103099178571526,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.7103099178571526,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.7103099178571526,
          "mrr": 0.611111111111111,
          "num_queries": 3,
          "num_candidates": 1006
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.017883008623749367,
          "num_queries": 3,
          "num_candidates": 1006
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.004201680672268907,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.3562071871080222,
          "mrr": 0.16666666666666666,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.08333333333333333,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/indunk": {
          "recall@1": 0.3076923076923077,
          "success@1": 0.3076923076923077,
          "ndcg@1": 0.3076923076923077,
          "recall@3": 0.38461538461538464,
          "success@3": 0.38461538461538464,
          "ndcg@3": 0.35622536565934293,
          "recall@5": 0.5384615384615384,
          "success@5": 0.5384615384615384,
          "ndcg@5": 0.42248329767063414,
          "recall@10": 0.6923076923076923,
          "success@10": 0.6923076923076923,
          "ndcg@10": 0.47239085229517735,
          "mrr": 0.4074723429004426,
          "num_queries": 13,
          "num_candidates": 1006
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.034482758620689655,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.02702702702702703,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.6363636363636364,
          "success@3": 0.6363636363636364,
          "ndcg@3": 0.5454545454545454,
          "recall@5": 0.6363636363636364,
          "success@5": 0.6363636363636364,
          "ndcg@5": 0.5454545454545454,
          "recall@10": 0.9090909090909091,
          "success@10": 0.9090909090909091,
          "ndcg@10": 0.6355064105550305,
          "mrr": 0.5566378066378067,
          "num_queries": 11,
          "num_candidates": 1006
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.04579939668174962,
          "num_queries": 4,
          "num_candidates": 1006
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1006
        },
        "ecommerce_reviews": {
          "recall@1": 0.1282051282051282,
          "success@1": 0.1282051282051282,
          "ndcg@1": 0.1282051282051282,
          "recall@3": 0.28205128205128205,
          "success@3": 0.28205128205128205,
          "ndcg@3": 0.21184255146520295,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.23392852880230003,
          "recall@10": 0.5384615384615384,
          "success@10": 0.5384615384615384,
          "ndcg@10": 0.3045371953432704,
          "mrr": 0.25353980486001926,
          "num_queries": 39,
          "num_candidates": 1006
        },
        "research_paper": {
          "recall@1": 0.8,
          "success@1": 0.8,
          "ndcg@1": 0.8,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.9,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.9,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.9,
          "mrr": 0.8666666666666666,
          "num_queries": 5,
          "num_candidates": 1006
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.16666666666666666,
          "mrr": 0.07818532818532818,
          "num_queries": 2,
          "num_candidates": 1006
        },
        "media_reviews/douban": {
          "recall@1": 0.07272727272727272,
          "success@1": 0.07272727272727272,
          "ndcg@1": 0.07272727272727272,
          "recall@3": 0.14545454545454545,
          "success@3": 0.14545454545454545,
          "ndcg@3": 0.1138519910389621,
          "recall@5": 0.16363636363636364,
          "success@5": 0.18181818181818182,
          "ndcg@5": 0.1229659153179055,
          "recall@10": 0.3090909090909091,
          "success@10": 0.32727272727272727,
          "ndcg@10": 0.16917322855970265,
          "mrr": 0.1530229732761935,
          "num_queries": 55,
          "num_candidates": 1006
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8214285714285714,
          "success@5": 0.8214285714285714,
          "ndcg@5": 0.8214285714285714,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8445999360756807,
          "mrr": 0.8344214713857571,
          "num_queries": 28,
          "num_candidates": 1006
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.3984375,
          "success@1": 0.40625,
          "ndcg@1": 0.40625,
          "recall@3": 0.5638020833333334,
          "success@3": 0.5703125,
          "ndcg@3": 0.4946123227107424,
          "recall@5": 0.62890625,
          "success@5": 0.6328125,
          "ndcg@5": 0.521719023290782,
          "recall@10": 0.7434895833333334,
          "success@10": 0.7473958333333334,
          "ndcg@10": 0.5590571175613853,
          "mrr": 0.5152965685063299,
          "num_queries": 384,
          "num_candidates": 1006
        },
        "medium": {
          "recall@1": 0.2919921875,
          "success@1": 0.298828125,
          "ndcg@1": 0.298828125,
          "recall@3": 0.416015625,
          "success@3": 0.421875,
          "ndcg@3": 0.3656807745110937,
          "recall@5": 0.4794921875,
          "success@5": 0.486328125,
          "ndcg@5": 0.3919677881743883,
          "recall@10": 0.6103515625,
          "success@10": 0.61328125,
          "ndcg@10": 0.4350509997017353,
          "mrr": 0.3990250504192564,
          "num_queries": 512,
          "num_candidates": 1006
        },
        "short": {
          "recall@1": 0.2152777777777778,
          "success@1": 0.2222222222222222,
          "ndcg@1": 0.2222222222222222,
          "recall@3": 0.2916666666666667,
          "success@3": 0.2916666666666667,
          "ndcg@3": 0.25876291324404804,
          "recall@5": 0.3541666666666667,
          "success@5": 0.3611111111111111,
          "ndcg@5": 0.2857483382999829,
          "recall@10": 0.4861111111111111,
          "success@10": 0.5,
          "ndcg@10": 0.32932919034661984,
          "mrr": 0.29663273914805455,
          "num_queries": 72,
          "num_candidates": 1006
        },
        "extra_long": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.375,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.375,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5531035935540111,
          "mrr": 0.4166666666666667,
          "num_queries": 4,
          "num_candidates": 1006
        }
      }
    },
    "attribution": {
      "eer": 0.0889917695473251,
      "num_queries": 972,
      "positive_pairs": 1008,
      "negative_pairs": 48600,
      "num_candidates": 1006,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "by_language": {
        "ar": {
          "eer": 0.08585858585858586,
          "num_queries": 189,
          "positive_pairs": 198,
          "negative_pairs": 9450
        },
        "de": {
          "eer": 0.032615384615384616,
          "num_queries": 65,
          "positive_pairs": 65,
          "negative_pairs": 3250
        },
        "en": {
          "eer": 0.07287671232876712,
          "num_queries": 146,
          "positive_pairs": 148,
          "negative_pairs": 7300
        },
        "fr": {
          "eer": 0.04709677419354839,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06198019801980198,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.025,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.015294117647058824,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.05154639175257732,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.06345864661654135,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.0737007874015748,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08541516245487364,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.022727272727272728,
          "num_queries": 38,
          "positive_pairs": 44,
          "negative_pairs": 1900
        },
        "social_media/politics": {
          "eer": 0.09433962264150944,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.10285714285714286,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.075,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.08771929824561403,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.06521739130434782,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.076,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.06896551724137931,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.08,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.076,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.058,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.047142857142857146,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.04964285714285714,
          "num_queries": 168,
          "positive_pairs": 177,
          "negative_pairs": 8400
        },
        "social_media/economy": {
          "eer": 0.01,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.006666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.31333333333333335,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.24,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.23076923076923078,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.01818181818181818,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.13,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.05128205128205128,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.004,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/investing": {
          "eer": 0.04,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.09454545454545454,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.05142857142857143,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06578125,
          "num_queries": 384,
          "positive_pairs": 401,
          "negative_pairs": 19200
        },
        "medium": {
          "eer": 0.0885546875,
          "num_queries": 512,
          "positive_pairs": 528,
          "negative_pairs": 25600
        },
        "short": {
          "eer": 0.11027777777777778,
          "num_queries": 72,
          "positive_pairs": 75,
          "negative_pairs": 3600
        },
        "extra_long": {
          "eer": 0.01,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        }
      }
    }
  }
}