{
  "llama3-8b-instruct": {
    "hf_repo": "meta-llama/Meta-Llama-3-8B-Instruct",
    "representation": {
      "recall@1": 0.31966403162055335,
      "success@1": 0.32707509881422925,
      "ndcg@1": 0.32707509881422925,
      "recall@3": 0.4535573122529644,
      "success@3": 0.45948616600790515,
      "ndcg@3": 0.39923472944949223,
      "recall@5": 0.5237154150197628,
      "success@5": 0.5296442687747036,
      "ndcg@5": 0.4283002569573744,
      "recall@10": 0.6413043478260869,
      "success@10": 0.6482213438735178,
      "ndcg@10": 0.46705187491198835,
      "mrr": 0.42909842908258433,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.1748768472906404,
          "success@1": 0.18719211822660098,
          "ndcg@1": 0.18719211822660098,
          "recall@3": 0.25862068965517243,
          "success@3": 0.270935960591133,
          "ndcg@3": 0.2272460913950983,
          "recall@5": 0.29310344827586204,
          "success@5": 0.3054187192118227,
          "ndcg@5": 0.24192946253336917,
          "recall@10": 0.4605911330049261,
          "success@10": 0.4876847290640394,
          "ndcg@10": 0.29706859877748765,
          "mrr": 0.2753088651662942,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.5211267605633803,
          "success@1": 0.5211267605633803,
          "ndcg@1": 0.5211267605633803,
          "recall@3": 0.6830985915492958,
          "success@3": 0.6901408450704225,
          "ndcg@3": 0.6151046666008914,
          "recall@5": 0.7535211267605634,
          "success@5": 0.7605633802816901,
          "ndcg@5": 0.643582293894559,
          "recall@10": 0.8450704225352113,
          "success@10": 0.8450704225352113,
          "ndcg@10": 0.6746323483488679,
          "mrr": 0.629626494340144,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.35240963855421686,
          "success@1": 0.3614457831325301,
          "ndcg@1": 0.3614457831325301,
          "recall@3": 0.5090361445783133,
          "success@3": 0.5120481927710844,
          "ndcg@3": 0.4462475511827549,
          "recall@5": 0.5662650602409639,
          "success@5": 0.5662650602409639,
          "ndcg@5": 0.46986826438178425,
          "recall@10": 0.6445783132530121,
          "success@10": 0.6445783132530121,
          "ndcg@10": 0.49515490851523813,
          "mrr": 0.4621051597446505,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.3790322580645161,
          "success@1": 0.3870967741935484,
          "ndcg@1": 0.3870967741935484,
          "recall@3": 0.532258064516129,
          "success@3": 0.532258064516129,
          "ndcg@3": 0.46812450023041663,
          "recall@5": 0.6290322580645161,
          "success@5": 0.6290322580645161,
          "ndcg@5": 0.5062687033634181,
          "recall@10": 0.7419354838709677,
          "success@10": 0.7419354838709677,
          "ndcg@10": 0.5427897125783706,
          "mrr": 0.4936808895432708,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.36633663366336633,
          "success@1": 0.38613861386138615,
          "ndcg@1": 0.38613861386138615,
          "recall@3": 0.5445544554455446,
          "success@3": 0.5544554455445545,
          "ndcg@3": 0.47283118666630275,
          "recall@5": 0.6336633663366337,
          "success@5": 0.6435643564356436,
          "ndcg@5": 0.509038813086761,
          "recall@10": 0.7524752475247525,
          "success@10": 0.7524752475247525,
          "ndcg@10": 0.5503945554812684,
          "mrr": 0.49892384278974466,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.425,
          "success@1": 0.425,
          "ndcg@1": 0.425,
          "recall@3": 0.725,
          "success@3": 0.725,
          "ndcg@3": 0.5979127068750051,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.6291178549595383,
          "recall@10": 0.9,
          "success@10": 0.9,
          "ndcg@10": 0.6586225960586318,
          "mrr": 0.5871833397337429,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.5588235294117647,
          "success@3": 0.5882352941176471,
          "ndcg@3": 0.466911961762011,
          "recall@5": 0.7352941176470589,
          "success@5": 0.7647058823529411,
          "ndcg@5": 0.5403358396079715,
          "recall@10": 0.9705882352941176,
          "success@10": 1.0,
          "ndcg@10": 0.6204071680982719,
          "mrr": 0.5177170868347339,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.30978260869565216,
          "success@1": 0.31521739130434784,
          "ndcg@1": 0.31521739130434784,
          "recall@3": 0.4076086956521739,
          "success@3": 0.41304347826086957,
          "ndcg@3": 0.36561811094620966,
          "recall@5": 0.4891304347826087,
          "success@5": 0.5,
          "ndcg@5": 0.4000125252680069,
          "recall@10": 0.5978260869565217,
          "success@10": 0.5978260869565217,
          "ndcg@10": 0.43675357912269125,
          "mrr": 0.4061630395111376,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.22556390977443608,
          "success@1": 0.22556390977443608,
          "ndcg@1": 0.22556390977443608,
          "recall@3": 0.37969924812030076,
          "success@3": 0.38345864661654133,
          "ndcg@3": 0.31645819250874807,
          "recall@5": 0.5037593984962406,
          "success@5": 0.5037593984962406,
          "ndcg@5": 0.36794786766570237,
          "recall@10": 0.6165413533834586,
          "success@10": 0.6165413533834586,
          "ndcg@10": 0.4038703379720862,
          "mrr": 0.35222499848470123,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.39763779527559057,
          "success@1": 0.4015748031496063,
          "ndcg@1": 0.4015748031496063,
          "recall@3": 0.4645669291338583,
          "success@3": 0.4645669291338583,
          "ndcg@3": 0.4392565237907775,
          "recall@5": 0.5,
          "success@5": 0.5039370078740157,
          "ndcg@5": 0.4546888383188316,
          "recall@10": 0.6062992125984252,
          "success@10": 0.6141732283464567,
          "ndcg@10": 0.48997037873814886,
          "mrr": 0.4680787497210918,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.3194945848375451,
          "success@1": 0.3249097472924188,
          "ndcg@1": 0.3249097472924188,
          "recall@3": 0.4657039711191336,
          "success@3": 0.4729241877256318,
          "ndcg@3": 0.40494312496082574,
          "recall@5": 0.5523465703971119,
          "success@5": 0.5595667870036101,
          "ndcg@5": 0.4407726029817735,
          "recall@10": 0.6877256317689531,
          "success@10": 0.6895306859205776,
          "ndcg@10": 0.4852539707970468,
          "mrr": 0.4374539689222932,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.10576923076923077,
          "success@1": 0.1346153846153846,
          "ndcg@1": 0.1346153846153846,
          "recall@3": 0.25961538461538464,
          "success@3": 0.28846153846153844,
          "ndcg@3": 0.20169526716680447,
          "recall@5": 0.2692307692307692,
          "success@5": 0.28846153846153844,
          "ndcg@5": 0.20677350029320044,
          "recall@10": 0.46153846153846156,
          "success@10": 0.5576923076923077,
          "ndcg@10": 0.2710805419584273,
          "mrr": 0.2486570260333719,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.40384615384615385,
          "success@1": 0.40384615384615385,
          "ndcg@1": 0.40384615384615385,
          "recall@3": 0.5576923076923077,
          "success@3": 0.5576923076923077,
          "ndcg@3": 0.4958765100274759,
          "recall@5": 0.5865384615384616,
          "success@5": 0.5961538461538461,
          "ndcg@5": 0.5083942202160746,
          "recall@10": 0.6442307692307693,
          "success@10": 0.6538461538461539,
          "ndcg@10": 0.5266601472503638,
          "mrr": 0.5011196411462353,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.2857142857142857,
          "success@1": 0.2857142857142857,
          "ndcg@1": 0.2857142857142857,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.4659799295918451,
          "recall@5": 0.7142857142857143,
          "success@5": 0.7142857142857143,
          "ndcg@5": 0.5275051521737584,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.568800127362028,
          "mrr": 0.47922374429223746,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.21794871794871795,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.2692307692307692,
          "success@3": 0.28205128205128205,
          "ndcg@3": 0.2532052999976506,
          "recall@5": 0.34615384615384615,
          "success@5": 0.358974358974359,
          "ndcg@5": 0.28408689416540645,
          "recall@10": 0.46153846153846156,
          "success@10": 0.46153846153846156,
          "ndcg@10": 0.3219031943454621,
          "mrr": 0.30827560909260954,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.804418536224494,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.804418536224494,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.804418536224494,
          "mrr": 0.7862616310892172,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.30357142857142855,
          "success@1": 0.30357142857142855,
          "ndcg@1": 0.30357142857142855,
          "recall@3": 0.39285714285714285,
          "success@3": 0.39285714285714285,
          "ndcg@3": 0.3552283796556138,
          "recall@5": 0.4642857142857143,
          "success@5": 0.4642857142857143,
          "ndcg@5": 0.38520842396730526,
          "recall@10": 0.5178571428571429,
          "success@10": 0.5178571428571429,
          "ndcg@10": 0.4018505623465095,
          "mrr": 0.38408309528404166,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.35555555555555557,
          "success@1": 0.35555555555555557,
          "ndcg@1": 0.35555555555555557,
          "recall@3": 0.4444444444444444,
          "success@3": 0.4444444444444444,
          "ndcg@3": 0.40581910015873146,
          "recall@5": 0.4666666666666667,
          "success@5": 0.4666666666666667,
          "ndcg@5": 0.4144158292083879,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.45816285475001184,
          "mrr": 0.4274127550553833,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.4,
          "success@3": 0.4,
          "ndcg@3": 0.33154648767857287,
          "recall@5": 0.4,
          "success@5": 0.4,
          "ndcg@5": 0.33154648767857287,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.39535657602844126,
          "mrr": 0.3507849803149437,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.41379310344827586,
          "success@1": 0.41379310344827586,
          "ndcg@1": 0.41379310344827586,
          "recall@3": 0.5517241379310345,
          "success@3": 0.5517241379310345,
          "ndcg@3": 0.49178825886699706,
          "recall@5": 0.6206896551724138,
          "success@5": 0.6206896551724138,
          "ndcg@5": 0.5184677628142068,
          "recall@10": 0.6896551724137931,
          "success@10": 0.6896551724137931,
          "ndcg@10": 0.5393136146453661,
          "mrr": 0.5065380866597905,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.20833333333333334,
          "success@1": 0.20833333333333334,
          "ndcg@1": 0.20833333333333334,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.28174414613095483,
          "recall@5": 0.375,
          "success@5": 0.375,
          "ndcg@5": 0.29968900271734616,
          "recall@10": 0.4583333333333333,
          "success@10": 0.4583333333333333,
          "ndcg@10": 0.329372934976348,
          "mrr": 0.3113429080313714,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.6676145339652448,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.55,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.5886852807234542,
          "recall@10": 0.7,
          "success@10": 0.7,
          "ndcg@10": 0.5886852807234542,
          "mrr": 0.5675558213716109,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.42857142857142855,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.3401328219387797,
          "recall@5": 0.42857142857142855,
          "success@5": 0.42857142857142855,
          "ndcg@5": 0.3401328219387797,
          "recall@10": 0.6428571428571429,
          "success@10": 0.6428571428571429,
          "ndcg@10": 0.41319524006554315,
          "mrr": 0.3572756532739675,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.34770114942528735,
          "success@1": 0.3620689655172414,
          "ndcg@1": 0.3620689655172414,
          "recall@3": 0.49712643678160917,
          "success@3": 0.5057471264367817,
          "ndcg@3": 0.43849110016315174,
          "recall@5": 0.6235632183908046,
          "success@5": 0.632183908045977,
          "ndcg@5": 0.4904258517104281,
          "recall@10": 0.764367816091954,
          "success@10": 0.764367816091954,
          "ndcg@10": 0.5375234398491905,
          "mrr": 0.4805286301523614,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.8333333333333334,
          "success@3": 0.8333333333333334,
          "ndcg@3": 0.6666666666666666,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.6666666666666666,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.7222222222222222,
          "mrr": 0.6349206349206349,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.010101010101010102,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.643558852691131,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.643558852691131,
          "mrr": 0.5277777777777778,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.023600643151442068,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.004975124378109453,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.05,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.3076923076923077,
          "success@1": 0.3076923076923077,
          "ndcg@1": 0.3076923076923077,
          "recall@3": 0.46153846153846156,
          "success@3": 0.46153846153846156,
          "ndcg@3": 0.4047584236263781,
          "recall@5": 0.6923076923076923,
          "success@5": 0.6923076923076923,
          "ndcg@5": 0.5007742638864803,
          "recall@10": 0.6923076923076923,
          "success@10": 0.6923076923076923,
          "ndcg@10": 0.5007742638864803,
          "mrr": 0.4408560438118634,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.022222222222222223,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.021739130434782608,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.5454545454545454,
          "success@3": 0.5454545454545454,
          "ndcg@3": 0.5,
          "recall@5": 0.5454545454545454,
          "success@5": 0.5454545454545454,
          "ndcg@5": 0.5,
          "recall@10": 0.9090909090909091,
          "success@10": 0.9090909090909091,
          "ndcg@10": 0.6216671573236744,
          "mrr": 0.5394518272425249,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.030212842712842712,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.09090909090909091,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.1282051282051282,
          "success@1": 0.1282051282051282,
          "ndcg@1": 0.1282051282051282,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2509122697802243,
          "recall@5": 0.38461538461538464,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.27075087527943154,
          "recall@10": 0.48717948717948717,
          "success@10": 0.48717948717948717,
          "ndcg@10": 0.3032552386916657,
          "mrr": 0.26859299540999654,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.78,
          "success@1": 0.8,
          "ndcg@1": 0.8,
          "recall@3": 0.86,
          "success@3": 0.88,
          "ndcg@3": 0.8297630778534767,
          "recall@5": 0.88,
          "success@5": 0.88,
          "ndcg@5": 0.8403258027563802,
          "recall@10": 0.88,
          "success@10": 0.88,
          "ndcg@10": 0.8403258027563802,
          "mrr": 0.8390824888307725,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.1781035935540111,
          "mrr": 0.08865248226950354,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.07272727272727272,
          "success@1": 0.07272727272727272,
          "ndcg@1": 0.07272727272727272,
          "recall@3": 0.14545454545454545,
          "success@3": 0.14545454545454545,
          "ndcg@3": 0.11623253201298861,
          "recall@5": 0.19090909090909092,
          "success@5": 0.2,
          "ndcg@5": 0.13620618344782645,
          "recall@10": 0.32727272727272727,
          "success@10": 0.34545454545454546,
          "ndcg@10": 0.1819336988262731,
          "mrr": 0.16006753698324935,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.8368098770740497,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8480764798163972,
          "mrr": 0.8371427606737686,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.3798449612403101,
          "success@1": 0.3875968992248062,
          "ndcg@1": 0.3875968992248062,
          "recall@3": 0.5361757105943152,
          "success@3": 0.5400516795865633,
          "ndcg@3": 0.472958992625485,
          "recall@5": 0.6020671834625323,
          "success@5": 0.6072351421188631,
          "ndcg@5": 0.5004874723616436,
          "recall@10": 0.7351421188630491,
          "success@10": 0.7390180878552972,
          "ndcg@10": 0.5450168987080852,
          "mrr": 0.4988506111558506,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.2887189292543021,
          "success@1": 0.2944550669216061,
          "ndcg@1": 0.2944550669216061,
          "recall@3": 0.4130019120458891,
          "success@3": 0.4187380497131931,
          "ndcg@3": 0.3615859902551332,
          "recall@5": 0.48565965583174,
          "success@5": 0.491395793499044,
          "ndcg@5": 0.3913884642074922,
          "recall@10": 0.5994263862332696,
          "success@10": 0.6042065009560229,
          "ndcg@10": 0.4282933668222974,
          "mrr": 0.3932822683684331,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.24,
          "success@1": 0.25333333333333335,
          "ndcg@1": 0.25333333333333335,
          "recall@3": 0.32666666666666666,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2951582160940172,
          "recall@5": 0.42,
          "success@5": 0.4266666666666667,
          "ndcg@5": 0.3339586184997083,
          "recall@10": 0.47333333333333333,
          "success@10": 0.48,
          "ndcg@10": 0.35066965734267747,
          "mrr": 0.329560692391588,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.2777777777777778,
          "success@1": 0.2962962962962963,
          "ndcg@1": 0.2962962962962963,
          "recall@3": 0.4074074074074074,
          "success@3": 0.4444444444444444,
          "ndcg@3": 0.3608917387532191,
          "recall@5": 0.42592592592592593,
          "success@5": 0.4444444444444444,
          "ndcg@5": 0.370672039589241,
          "recall@10": 0.5740740740740741,
          "success@10": 0.6666666666666666,
          "ndcg@10": 0.4236037948940975,
          "mrr": 0.3995831640074678,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.08604743083003953,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.0870935960591133,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.041666666666666664,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.07626506024096386,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.04064516129032258,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06542056074766354,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.025,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.010588235294117647,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.05154639175257732,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.06255639097744362,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06456692913385827,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08710801393728224,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.04038461538461539,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.09384615384615384,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.10857142857142857,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.07179487179487179,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.08771929824561403,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.06521739130434782,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.089,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.06896551724137931,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.07333333333333333,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.064,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.054,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.03428571428571429,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.04862068965517241,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.006666666666666667,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.14,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.006666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.22,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.18,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.23076923076923078,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.08,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.01818181818181818,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.165,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.05128205128205128,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.0248,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.09,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.07854545454545454,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.06142857142857143,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06188118811881188,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.08577437858508605,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.10126582278481013,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.07692307692307693,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}