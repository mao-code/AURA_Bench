{
  "llama3.1-8b-instruct": {
    "hf_repo": "meta-llama/Llama-3.1-8B-Instruct",
    "representation": {
      "recall@1": 0.3221343873517787,
      "success@1": 0.3300395256916996,
      "ndcg@1": 0.3300395256916996,
      "recall@3": 0.450098814229249,
      "success@3": 0.4575098814229249,
      "ndcg@3": 0.39756775852489956,
      "recall@5": 0.5197628458498024,
      "success@5": 0.5266798418972332,
      "ndcg@5": 0.4269014869281777,
      "recall@10": 0.6348814229249012,
      "success@10": 0.6403162055335968,
      "ndcg@10": 0.46465681893391947,
      "mrr": 0.4289254242758772,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.1896551724137931,
          "success@1": 0.2019704433497537,
          "ndcg@1": 0.2019704433497537,
          "recall@3": 0.26354679802955666,
          "success@3": 0.28078817733990147,
          "ndcg@3": 0.23759732826918342,
          "recall@5": 0.29310344827586204,
          "success@5": 0.3103448275862069,
          "ndcg@5": 0.24967852636056348,
          "recall@10": 0.45566502463054187,
          "success@10": 0.4729064039408867,
          "ndcg@10": 0.3038812571120122,
          "mrr": 0.28722949765782896,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.5211267605633803,
          "success@1": 0.5211267605633803,
          "ndcg@1": 0.5211267605633803,
          "recall@3": 0.6830985915492958,
          "success@3": 0.6901408450704225,
          "ndcg@3": 0.610285811417867,
          "recall@5": 0.7394366197183099,
          "success@5": 0.7464788732394366,
          "ndcg@5": 0.6333148076237243,
          "recall@10": 0.8591549295774648,
          "success@10": 0.8591549295774648,
          "ndcg@10": 0.6725088377668087,
          "mrr": 0.6208418411122467,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.35240963855421686,
          "success@1": 0.3614457831325301,
          "ndcg@1": 0.3614457831325301,
          "recall@3": 0.47289156626506024,
          "success@3": 0.4759036144578313,
          "ndcg@3": 0.4242315947498797,
          "recall@5": 0.5301204819277109,
          "success@5": 0.5301204819277109,
          "ndcg@5": 0.44811630644793826,
          "recall@10": 0.6445783132530121,
          "success@10": 0.6445783132530121,
          "ndcg@10": 0.4856190906476679,
          "mrr": 0.45003032758753453,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.4112903225806452,
          "success@1": 0.41935483870967744,
          "ndcg@1": 0.41935483870967744,
          "recall@3": 0.5645161290322581,
          "success@3": 0.5645161290322581,
          "ndcg@3": 0.4940472540898622,
          "recall@5": 0.6451612903225806,
          "success@5": 0.6451612903225806,
          "ndcg@5": 0.5266587305068042,
          "recall@10": 0.7580645161290323,
          "success@10": 0.7580645161290323,
          "ndcg@10": 0.5629867531194004,
          "mrr": 0.5150966760091118,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.39603960396039606,
          "success@1": 0.4158415841584158,
          "ndcg@1": 0.4158415841584158,
          "recall@3": 0.5792079207920792,
          "success@3": 0.594059405940594,
          "ndcg@3": 0.5049507603924108,
          "recall@5": 0.6831683168316832,
          "success@5": 0.693069306930693,
          "ndcg@5": 0.5504715448452442,
          "recall@10": 0.7623762376237624,
          "success@10": 0.7623762376237624,
          "ndcg@10": 0.575849734365914,
          "mrr": 0.5292860853926775,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.375,
          "success@1": 0.375,
          "ndcg@1": 0.375,
          "recall@3": 0.7,
          "success@3": 0.7,
          "ndcg@3": 0.566959194553578,
          "recall@5": 0.85,
          "success@5": 0.85,
          "ndcg@5": 0.631560678264587,
          "recall@10": 0.875,
          "success@10": 0.875,
          "ndcg@10": 0.6390864281561865,
          "mrr": 0.5669498556998557,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.35294117647058826,
          "success@1": 0.35294117647058826,
          "ndcg@1": 0.35294117647058826,
          "recall@3": 0.4411764705882353,
          "success@3": 0.47058823529411764,
          "ndcg@3": 0.4080884323502463,
          "recall@5": 0.6176470588235294,
          "success@5": 0.6470588235294118,
          "ndcg@5": 0.48151231019620677,
          "recall@10": 0.9705882352941176,
          "success@10": 1.0,
          "ndcg@10": 0.6005919016261255,
          "mrr": 0.49523809523809537,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.29891304347826086,
          "success@1": 0.30434782608695654,
          "ndcg@1": 0.30434782608695654,
          "recall@3": 0.41847826086956524,
          "success@3": 0.42391304347826086,
          "ndcg@3": 0.36846440993689356,
          "recall@5": 0.5054347826086957,
          "success@5": 0.5108695652173914,
          "ndcg@5": 0.40448437003142546,
          "recall@10": 0.5869565217391305,
          "success@10": 0.5869565217391305,
          "ndcg@10": 0.43109560391592416,
          "mrr": 0.4014125157125038,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.22932330827067668,
          "success@1": 0.23308270676691728,
          "ndcg@1": 0.23308270676691728,
          "recall@3": 0.37218045112781956,
          "success@3": 0.37593984962406013,
          "ndcg@3": 0.31144695284571455,
          "recall@5": 0.47368421052631576,
          "success@5": 0.47368421052631576,
          "ndcg@5": 0.3545401267179713,
          "recall@10": 0.5939849624060151,
          "success@10": 0.5939849624060151,
          "ndcg@10": 0.39421111941119324,
          "mrr": 0.3496192561565609,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.37401574803149606,
          "success@1": 0.3779527559055118,
          "ndcg@1": 0.3779527559055118,
          "recall@3": 0.4566929133858268,
          "success@3": 0.4566929133858268,
          "ndcg@3": 0.42350849229471454,
          "recall@5": 0.49606299212598426,
          "success@5": 0.5039370078740157,
          "ndcg@5": 0.44032994556997246,
          "recall@10": 0.5787401574803149,
          "success@10": 0.5905511811023622,
          "ndcg@10": 0.4665630966789445,
          "mrr": 0.4492904987835347,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.3285198555956679,
          "success@1": 0.33574007220216606,
          "ndcg@1": 0.33574007220216606,
          "recall@3": 0.45126353790613716,
          "success@3": 0.4584837545126354,
          "ndcg@3": 0.40167729330724977,
          "recall@5": 0.5324909747292419,
          "success@5": 0.5379061371841155,
          "ndcg@5": 0.4357281281842953,
          "recall@10": 0.6714801444043321,
          "success@10": 0.6750902527075813,
          "ndcg@10": 0.48186290447854124,
          "mrr": 0.43915488206694986,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.125,
          "success@1": 0.15384615384615385,
          "ndcg@1": 0.15384615384615385,
          "recall@3": 0.23076923076923078,
          "success@3": 0.2692307692307692,
          "ndcg@3": 0.19774771887943066,
          "recall@5": 0.2692307692307692,
          "success@5": 0.3076923076923077,
          "ndcg@5": 0.21431018489429865,
          "recall@10": 0.4423076923076923,
          "success@10": 0.5,
          "ndcg@10": 0.27414538695932483,
          "mrr": 0.26328459844579755,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.4423076923076923,
          "success@1": 0.4423076923076923,
          "ndcg@1": 0.4423076923076923,
          "recall@3": 0.5673076923076923,
          "success@3": 0.5769230769230769,
          "ndcg@3": 0.5184850454661543,
          "recall@5": 0.6057692307692307,
          "success@5": 0.6153846153846154,
          "ndcg@5": 0.5342067640297683,
          "recall@10": 0.6442307692307693,
          "success@10": 0.6538461538461539,
          "ndcg@10": 0.5458323352432994,
          "mrr": 0.5273316054817461,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.5714285714285714,
          "success@3": 0.5714285714285714,
          "ndcg@3": 0.5187042505102083,
          "recall@5": 0.5714285714285714,
          "success@5": 0.5714285714285714,
          "ndcg@5": 0.5187042505102083,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.6172100391446876,
          "mrr": 0.5448700027956388,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.19230769230769232,
          "success@1": 0.20512820512820512,
          "ndcg@1": 0.20512820512820512,
          "recall@3": 0.2692307692307692,
          "success@3": 0.28205128205128205,
          "ndcg@3": 0.2403847871771378,
          "recall@5": 0.3717948717948718,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.28343305593238705,
          "recall@10": 0.5128205128205128,
          "success@10": 0.5128205128205128,
          "ndcg@10": 0.33011044635061315,
          "mrr": 0.3013084277628168,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.7142857142857143,
          "success@1": 0.7142857142857143,
          "ndcg@1": 0.7142857142857143,
          "recall@3": 0.8571428571428571,
          "success@3": 0.8571428571428571,
          "ndcg@3": 0.804418536224494,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.804418536224494,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.804418536224494,
          "mrr": 0.7862190812720848,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.4107142857142857,
          "success@3": 0.4107142857142857,
          "ndcg@3": 0.342047299426023,
          "recall@5": 0.4642857142857143,
          "success@5": 0.4642857142857143,
          "ndcg@5": 0.3643366909149753,
          "recall@10": 0.5535714285714286,
          "success@10": 0.5535714285714286,
          "ndcg@10": 0.39474713538499995,
          "mrr": 0.36049002071379477,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.37777777777777777,
          "success@1": 0.37777777777777777,
          "ndcg@1": 0.37777777777777777,
          "recall@3": 0.4222222222222222,
          "success@3": 0.4222222222222222,
          "ndcg@3": 0.40290955007936574,
          "recall@5": 0.5111111111111111,
          "success@5": 0.5111111111111111,
          "ndcg@5": 0.4402180496672484,
          "recall@10": 0.5777777777777777,
          "success@10": 0.5777777777777777,
          "ndcg@10": 0.46429595865234147,
          "mrr": 0.4422547695432983,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.31309297535714575,
          "recall@5": 0.4,
          "success@5": 0.4,
          "ndcg@5": 0.33243561571887287,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.3943802673239194,
          "mrr": 0.3517694869481728,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.4827586206896552,
          "success@1": 0.4827586206896552,
          "ndcg@1": 0.4827586206896552,
          "recall@3": 0.5172413793103449,
          "success@3": 0.5172413793103449,
          "ndcg@3": 0.5,
          "recall@5": 0.5862068965517241,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.5266795039472097,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.549051856020281,
          "mrr": 0.5307433590913471,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.20833333333333334,
          "success@1": 0.20833333333333334,
          "ndcg@1": 0.20833333333333334,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.2708333333333333,
          "recall@5": 0.4166666666666667,
          "success@5": 0.4166666666666667,
          "ndcg@5": 0.3048970568878306,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.33178339078057684,
          "mrr": 0.29740277293421086,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7,
          "mrr": 0.6676145339652448,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.6,
          "success@3": 0.6,
          "ndcg@3": 0.5630929753571458,
          "recall@5": 0.7,
          "success@5": 0.7,
          "ndcg@5": 0.606160631164485,
          "recall@10": 0.7,
          "success@10": 0.7,
          "ndcg@10": 0.606160631164485,
          "mrr": 0.5925373645961881,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.3758471076530654,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.3758471076530654,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.4457474895644399,
          "mrr": 0.37043750048814017,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.35344827586206895,
          "success@1": 0.367816091954023,
          "ndcg@1": 0.367816091954023,
          "recall@3": 0.5344827586206896,
          "success@3": 0.5459770114942529,
          "ndcg@3": 0.45879493913966674,
          "recall@5": 0.6235632183908046,
          "success@5": 0.632183908045977,
          "ndcg@5": 0.49734182574463365,
          "recall@10": 0.7586206896551724,
          "success@10": 0.7586206896551724,
          "ndcg@10": 0.5408161254315549,
          "mrr": 0.48702766015992405,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.5,
          "recall@5": 0.8333333333333334,
          "success@5": 0.8333333333333334,
          "ndcg@5": 0.5717794263455654,
          "recall@10": 0.8333333333333334,
          "success@10": 0.8333333333333334,
          "ndcg@10": 0.5717794263455654,
          "mrr": 0.5012626262626262,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0125,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.16666666666666666,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.4391764551026449,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.4391764551026449,
          "mrr": 0.2611111111111111,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.018549016737422534,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.004291845493562232,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.058823529411764705,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.23076923076923078,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.38461538461538464,
          "success@3": 0.38461538461538464,
          "ndcg@3": 0.32783534670330117,
          "recall@5": 0.5384615384615384,
          "success@5": 0.5384615384615384,
          "ndcg@5": 0.3907222209577576,
          "recall@10": 0.6923076923076923,
          "success@10": 0.6923076923076923,
          "ndcg@10": 0.4381449034538892,
          "mrr": 0.36250981437190777,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.027777777777777776,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.03333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.5454545454545454,
          "success@3": 0.5454545454545454,
          "ndcg@3": 0.5,
          "recall@5": 0.6363636363636364,
          "success@5": 0.6363636363636364,
          "ndcg@5": 0.5391524143703085,
          "recall@10": 0.8181818181818182,
          "success@10": 0.8181818181818182,
          "ndcg@10": 0.5941096601070008,
          "mrr": 0.538892168437623,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.04118492603956197,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.05555555555555555,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.5,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.5,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.5,
          "mrr": 0.3333333333333333,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.15384615384615385,
          "success@1": 0.15384615384615385,
          "ndcg@1": 0.15384615384615385,
          "recall@3": 0.3076923076923077,
          "success@3": 0.3076923076923077,
          "ndcg@3": 0.2408407502747275,
          "recall@5": 0.358974358974359,
          "success@5": 0.358974358974359,
          "ndcg@5": 0.2618030416928797,
          "recall@10": 0.5128205128205128,
          "success@10": 0.5128205128205128,
          "ndcg@10": 0.3131230211937498,
          "mrr": 0.2727035563921606,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.78,
          "success@1": 0.8,
          "ndcg@1": 0.8,
          "recall@3": 0.86,
          "success@3": 0.88,
          "ndcg@3": 0.8297630778534767,
          "recall@5": 0.88,
          "success@5": 0.88,
          "ndcg@5": 0.8403258027563802,
          "recall@10": 0.88,
          "success@10": 0.88,
          "ndcg@10": 0.8403258027563802,
          "mrr": 0.8389168573607932,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.16666666666666666,
          "mrr": 0.07669172932330827,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.05454545454545454,
          "success@1": 0.05454545454545454,
          "ndcg@1": 0.05454545454545454,
          "recall@3": 0.14545454545454545,
          "success@3": 0.14545454545454545,
          "ndcg@3": 0.104761081948053,
          "recall@5": 0.18181818181818182,
          "success@5": 0.2,
          "ndcg@5": 0.1209086936312608,
          "recall@10": 0.2727272727272727,
          "success@10": 0.2909090909090909,
          "ndcg@10": 0.148102412190342,
          "mrr": 0.13940825388399972,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.8035714285714286,
          "success@1": 0.8214285714285714,
          "ndcg@1": 0.8214285714285714,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8214285714285714,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.8352447431155193,
          "recall@10": 0.8928571428571429,
          "success@10": 0.8928571428571429,
          "ndcg@10": 0.8455684869125868,
          "mrr": 0.8378623188405797,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.3875968992248062,
          "success@1": 0.3953488372093023,
          "ndcg@1": 0.3953488372093023,
          "recall@3": 0.5529715762273901,
          "success@3": 0.5581395348837209,
          "ndcg@3": 0.4848792696093751,
          "recall@5": 0.6046511627906976,
          "success@5": 0.6098191214470284,
          "ndcg@5": 0.5072050756071793,
          "recall@10": 0.7170542635658915,
          "success@10": 0.7209302325581395,
          "ndcg@10": 0.5439078596595992,
          "mrr": 0.5044471435838462,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.29349904397705545,
          "success@1": 0.30019120458891013,
          "ndcg@1": 0.30019120458891013,
          "recall@3": 0.4005736137667304,
          "success@3": 0.4072657743785851,
          "ndcg@3": 0.3568007184775074,
          "recall@5": 0.4837476099426386,
          "success@5": 0.4894837476099426,
          "ndcg@5": 0.3913416780987266,
          "recall@10": 0.5984703632887189,
          "success@10": 0.6022944550669216,
          "ndcg@10": 0.4287025624677697,
          "mrr": 0.3945785114676278,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.21333333333333335,
          "success@1": 0.22666666666666666,
          "ndcg@1": 0.22666666666666666,
          "recall@3": 0.2733333333333333,
          "success@3": 0.28,
          "ndcg@3": 0.24817529590353946,
          "recall@5": 0.36666666666666664,
          "success@5": 0.37333333333333335,
          "ndcg@5": 0.2879182871177926,
          "recall@10": 0.4866666666666667,
          "success@10": 0.49333333333333335,
          "ndcg@10": 0.32771948637806275,
          "mrr": 0.2978538459678342,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.24074074074074073,
          "success@1": 0.25925925925925924,
          "ndcg@1": 0.25925925925925924,
          "recall@3": 0.42592592592592593,
          "success@3": 0.48148148148148145,
          "ndcg@3": 0.3507544937728827,
          "recall@5": 0.42592592592592593,
          "success@5": 0.48148148148148145,
          "ndcg@5": 0.3507544937728827,
          "recall@10": 0.5740740740740741,
          "success@10": 0.6296296296296297,
          "ndcg@10": 0.405553978661587,
          "mrr": 0.37584758722529615,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.08484189723320158,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.08009852216748768,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.041666666666666664,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.07692307692307693,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.045806451612903226,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06542056074766354,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.025,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.012941176470588235,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.05304347826086957,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.06569343065693431,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06692913385826772,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.08362369337979095,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.03769230769230769,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.09433962264150944,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.10857142857142857,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.075,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.08857142857142856,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.06521739130434782,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.082,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.08137931034482758,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.07166666666666667,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.064,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.076,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.0,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.05,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.04891304347826087,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.016666666666666666,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.12,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.0,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.17333333333333334,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.24,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.23076923076923078,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.08,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.06,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.01818181818181818,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.235,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.05333333333333334,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.0264,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.09,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.08036363636363636,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.03571428571428571,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06435643564356436,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.0832887189292543,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.09973333333333333,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.09259259259259259,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}