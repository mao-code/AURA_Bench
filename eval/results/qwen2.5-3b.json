{
  "qwen2.5-3b": {
    "hf_repo": "Qwen/Qwen2.5-3B",
    "representation": {
      "recall@1": 0.2826086956521739,
      "success@1": 0.29051383399209485,
      "ndcg@1": 0.29051383399209485,
      "recall@3": 0.4209486166007905,
      "success@3": 0.4288537549407115,
      "ndcg@3": 0.3659818657845792,
      "recall@5": 0.4881422924901186,
      "success@5": 0.49604743083003955,
      "ndcg@5": 0.3940136527849552,
      "recall@10": 0.5938735177865613,
      "success@10": 0.5978260869565217,
      "ndcg@10": 0.42819862734652325,
      "mrr": 0.39552504446625786,
      "num_queries": 1012,
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "recall@1": 0.16995073891625614,
          "success@1": 0.18226600985221675,
          "ndcg@1": 0.18226600985221675,
          "recall@3": 0.2684729064039409,
          "success@3": 0.28078817733990147,
          "ndcg@3": 0.22979674440399486,
          "recall@5": 0.3275862068965517,
          "success@5": 0.3448275862068966,
          "ndcg@5": 0.2553037930851515,
          "recall@10": 0.47044334975369456,
          "success@10": 0.4827586206896552,
          "ndcg@10": 0.30191789882364595,
          "mrr": 0.2769517412919467,
          "num_queries": 203,
          "num_candidates": 1059
        },
        "de": {
          "recall@1": 0.33098591549295775,
          "success@1": 0.3380281690140845,
          "ndcg@1": 0.3380281690140845,
          "recall@3": 0.5422535211267606,
          "success@3": 0.5492957746478874,
          "ndcg@3": 0.4566541511053526,
          "recall@5": 0.6267605633802817,
          "success@5": 0.6338028169014085,
          "ndcg@5": 0.49058040948683085,
          "recall@10": 0.7535211267605634,
          "success@10": 0.7605633802816901,
          "ndcg@10": 0.53076830960502,
          "mrr": 0.4770025573757128,
          "num_queries": 71,
          "num_candidates": 1059
        },
        "en": {
          "recall@1": 0.3102409638554217,
          "success@1": 0.3192771084337349,
          "ndcg@1": 0.3192771084337349,
          "recall@3": 0.4126506024096386,
          "success@3": 0.41566265060240964,
          "ndcg@3": 0.37096569885834524,
          "recall@5": 0.45481927710843373,
          "success@5": 0.4578313253012048,
          "ndcg@5": 0.3885987615380805,
          "recall@10": 0.5120481927710844,
          "success@10": 0.5120481927710844,
          "ndcg@10": 0.40763909407502347,
          "mrr": 0.39456335193863734,
          "num_queries": 166,
          "num_candidates": 1059
        },
        "fr": {
          "recall@1": 0.3951612903225806,
          "success@1": 0.4032258064516129,
          "ndcg@1": 0.4032258064516129,
          "recall@3": 0.5483870967741935,
          "success@3": 0.5483870967741935,
          "ndcg@3": 0.4905888431451646,
          "recall@5": 0.6290322580645161,
          "success@5": 0.6290322580645161,
          "ndcg@5": 0.5246139889440051,
          "recall@10": 0.6774193548387096,
          "success@10": 0.6774193548387096,
          "ndcg@10": 0.5389869698737769,
          "mrr": 0.5086116822059984,
          "num_queries": 62,
          "num_candidates": 1059
        },
        "es": {
          "recall@1": 0.2722772277227723,
          "success@1": 0.2871287128712871,
          "ndcg@1": 0.2871287128712871,
          "recall@3": 0.5346534653465347,
          "success@3": 0.5544554455445545,
          "ndcg@3": 0.4311630181010412,
          "recall@5": 0.5891089108910891,
          "success@5": 0.594059405940594,
          "ndcg@5": 0.45553103572881104,
          "recall@10": 0.6831683168316832,
          "success@10": 0.6831683168316832,
          "ndcg@10": 0.4868209897806969,
          "mrr": 0.4381383470160418,
          "num_queries": 101,
          "num_candidates": 1059
        },
        "hi": {
          "recall@1": 0.375,
          "success@1": 0.375,
          "ndcg@1": 0.375,
          "recall@3": 0.525,
          "success@3": 0.525,
          "ndcg@3": 0.46636621919643223,
          "recall@5": 0.6,
          "success@5": 0.6,
          "ndcg@5": 0.4975713672809654,
          "recall@10": 0.725,
          "success@10": 0.725,
          "ndcg@10": 0.5381947134085318,
          "mrr": 0.4973592861386978,
          "num_queries": 40,
          "num_candidates": 1059
        },
        "ja": {
          "recall@1": 0.4117647058823529,
          "success@1": 0.4117647058823529,
          "ndcg@1": 0.4117647058823529,
          "recall@3": 0.5588235294117647,
          "success@3": 0.5882352941176471,
          "ndcg@3": 0.5010460329885882,
          "recall@5": 0.8529411764705882,
          "success@5": 0.8823529411764706,
          "ndcg@5": 0.6199820058033183,
          "recall@10": 0.9411764705882353,
          "success@10": 0.9411764705882353,
          "ndcg@10": 0.6500156893396348,
          "mrr": 0.5672268907563025,
          "num_queries": 17,
          "num_candidates": 1059
        },
        "ko": {
          "recall@1": 0.28804347826086957,
          "success@1": 0.29347826086956524,
          "ndcg@1": 0.29347826086956524,
          "recall@3": 0.3858695652173913,
          "success@3": 0.391304347826087,
          "ndcg@3": 0.34814842899745285,
          "recall@5": 0.4782608695652174,
          "success@5": 0.4891304347826087,
          "ndcg@5": 0.385318729783576,
          "recall@10": 0.5760869565217391,
          "success@10": 0.5760869565217391,
          "ndcg@10": 0.41655169486840293,
          "mrr": 0.38727112399678065,
          "num_queries": 92,
          "num_candidates": 1059
        },
        "ru": {
          "recall@1": 0.22180451127819548,
          "success@1": 0.22556390977443608,
          "ndcg@1": 0.22556390977443608,
          "recall@3": 0.35714285714285715,
          "success@3": 0.3684210526315789,
          "ndcg@3": 0.30162309121877673,
          "recall@5": 0.43609022556390975,
          "success@5": 0.44360902255639095,
          "ndcg@5": 0.33401325060429116,
          "recall@10": 0.5902255639097744,
          "success@10": 0.5939849624060151,
          "ndcg@10": 0.38286515094497464,
          "mrr": 0.3387282918706852,
          "num_queries": 133,
          "num_candidates": 1059
        },
        "zh": {
          "recall@1": 0.3661417322834646,
          "success@1": 0.3700787401574803,
          "ndcg@1": 0.3700787401574803,
          "recall@3": 0.49606299212598426,
          "success@3": 0.49606299212598426,
          "ndcg@3": 0.44441123849831526,
          "recall@5": 0.5393700787401575,
          "success@5": 0.5433070866141733,
          "ndcg@5": 0.46241107834416567,
          "recall@10": 0.6259842519685039,
          "success@10": 0.6299212598425197,
          "ndcg@10": 0.49044920831776934,
          "mrr": 0.4620670185968272,
          "num_queries": 127,
          "num_candidates": 1059
        }
      },
      "by_genre": {
        "news": {
          "recall@1": 0.2743682310469314,
          "success@1": 0.2815884476534296,
          "ndcg@1": 0.2815884476534296,
          "recall@3": 0.43862815884476536,
          "success@3": 0.44765342960288806,
          "ndcg@3": 0.37284902632767575,
          "recall@5": 0.51985559566787,
          "success@5": 0.5306859205776173,
          "ndcg@5": 0.4060121923216025,
          "recall@10": 0.6191335740072202,
          "success@10": 0.6209386281588448,
          "ndcg@10": 0.43824311260586135,
          "mrr": 0.4013860333028874,
          "num_queries": 277,
          "num_candidates": 1059
        },
        "poetry": {
          "recall@1": 0.08653846153846154,
          "success@1": 0.11538461538461539,
          "ndcg@1": 0.11538461538461539,
          "recall@3": 0.20192307692307693,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.16609358090483248,
          "recall@5": 0.25961538461538464,
          "success@5": 0.3076923076923077,
          "ndcg@5": 0.19281453016044722,
          "recall@10": 0.4519230769230769,
          "success@10": 0.5,
          "ndcg@10": 0.25795306416724545,
          "mrr": 0.23451529812721422,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/politics": {
          "recall@1": 0.34615384615384615,
          "success@1": 0.34615384615384615,
          "ndcg@1": 0.34615384615384615,
          "recall@3": 0.4807692307692308,
          "success@3": 0.4807692307692308,
          "ndcg@3": 0.4285688177197836,
          "recall@5": 0.5192307692307693,
          "success@5": 0.5192307692307693,
          "ndcg@5": 0.4442905362833977,
          "recall@10": 0.5961538461538461,
          "success@10": 0.5961538461538461,
          "ndcg@10": 0.4698464833346623,
          "mrr": 0.44708565682983586,
          "num_queries": 52,
          "num_candidates": 1059
        },
        "social_media/business": {
          "recall@1": 0.42857142857142855,
          "success@1": 0.42857142857142855,
          "ndcg@1": 0.42857142857142855,
          "recall@3": 0.42857142857142855,
          "success@3": 0.42857142857142855,
          "ndcg@3": 0.42857142857142855,
          "recall@5": 0.5714285714285714,
          "success@5": 0.5714285714285714,
          "ndcg@5": 0.49009665115334183,
          "recall@10": 0.5714285714285714,
          "success@10": 0.5714285714285714,
          "ndcg@10": 0.49009665115334183,
          "mrr": 0.47503786536044595,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/sports": {
          "recall@1": 0.16666666666666666,
          "success@1": 0.1794871794871795,
          "ndcg@1": 0.1794871794871795,
          "recall@3": 0.32051282051282054,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.24649095366065277,
          "recall@5": 0.4230769230769231,
          "success@5": 0.4358974358974359,
          "ndcg@5": 0.290662908334847,
          "recall@10": 0.5641025641025641,
          "success@10": 0.5641025641025641,
          "ndcg@10": 0.33488082434880806,
          "mrr": 0.2898965147483487,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "social_media/cryptocurrency": {
          "recall@1": 0.5714285714285714,
          "success@1": 0.5714285714285714,
          "ndcg@1": 0.5714285714285714,
          "recall@3": 0.7142857142857143,
          "success@3": 0.7142857142857143,
          "ndcg@3": 0.6615613933673511,
          "recall@5": 0.8571428571428571,
          "success@5": 0.8571428571428571,
          "ndcg@5": 0.7168260801151428,
          "recall@10": 0.8571428571428571,
          "success@10": 0.8571428571428571,
          "ndcg@10": 0.7168260801151428,
          "mrr": 0.6719999999999999,
          "num_queries": 7,
          "num_candidates": 1059
        },
        "social_media/people": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.3392857142857143,
          "success@3": 0.3392857142857143,
          "ndcg@3": 0.30399498239796124,
          "recall@5": 0.4642857142857143,
          "success@5": 0.4642857142857143,
          "ndcg@5": 0.35548185121933973,
          "recall@10": 0.5535714285714286,
          "success@10": 0.5535714285714286,
          "ndcg@10": 0.3819322019269776,
          "mrr": 0.341723585922124,
          "num_queries": 56,
          "num_candidates": 1059
        },
        "social_media/entertainment": {
          "recall@1": 0.2222222222222222,
          "success@1": 0.2222222222222222,
          "ndcg@1": 0.2222222222222222,
          "recall@3": 0.34444444444444444,
          "success@3": 0.35555555555555557,
          "ndcg@3": 0.29622872468152356,
          "recall@5": 0.4,
          "success@5": 0.4,
          "ndcg@5": 0.32123808554195415,
          "recall@10": 0.4888888888888889,
          "success@10": 0.4888888888888889,
          "ndcg@10": 0.34975278641120694,
          "mrr": 0.32648161073777,
          "num_queries": 45,
          "num_candidates": 1059
        },
        "social_media/environment": {
          "recall@1": 0.25,
          "success@1": 0.25,
          "ndcg@1": 0.25,
          "recall@3": 0.35,
          "success@3": 0.35,
          "ndcg@3": 0.31309297535714575,
          "recall@5": 0.4,
          "success@5": 0.4,
          "ndcg@5": 0.33243561571887287,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.39480221595656645,
          "mrr": 0.3492320412470612,
          "num_queries": 20,
          "num_candidates": 1059
        },
        "social_media/technology": {
          "recall@1": 0.3793103448275862,
          "success@1": 0.3793103448275862,
          "ndcg@1": 0.3793103448275862,
          "recall@3": 0.5862068965517241,
          "success@3": 0.5862068965517241,
          "ndcg@3": 0.496303077955668,
          "recall@5": 0.5862068965517241,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.496303077955668,
          "recall@10": 0.6551724137931034,
          "success@10": 0.6551724137931034,
          "ndcg@10": 0.5192915837027945,
          "mrr": 0.48963333662360414,
          "num_queries": 29,
          "num_candidates": 1059
        },
        "social_media/social": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.3333333333333333,
          "recall@5": 0.375,
          "success@5": 0.375,
          "ndcg@5": 0.34945220030143925,
          "recall@10": 0.375,
          "success@10": 0.375,
          "ndcg@10": 0.34945220030143925,
          "mrr": 0.36316901190651535,
          "num_queries": 24,
          "num_candidates": 1059
        },
        "social_media/finance": {
          "recall@1": 0.6,
          "success@1": 0.6,
          "ndcg@1": 0.6,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7261859507142916,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7261859507142916,
          "recall@10": 0.8,
          "success@10": 0.8,
          "ndcg@10": 0.7261859507142916,
          "mrr": 0.7009174311926605,
          "num_queries": 5,
          "num_candidates": 1059
        },
        "social_media/health": {
          "recall@1": 0.5,
          "success@1": 0.5,
          "ndcg@1": 0.5,
          "recall@3": 0.5,
          "success@3": 0.5,
          "ndcg@3": 0.5,
          "recall@5": 0.5,
          "success@5": 0.5,
          "ndcg@5": 0.5,
          "recall@10": 0.6,
          "success@10": 0.6,
          "ndcg@10": 0.5315464876785729,
          "mrr": 0.5270252100840336,
          "num_queries": 10,
          "num_candidates": 1059
        },
        "social_media/law": {
          "recall@1": 1.0,
          "success@1": 1.0,
          "ndcg@1": 1.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 1.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 1.0,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 1.0,
          "mrr": 1.0,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "social_media/science": {
          "recall@1": 0.21428571428571427,
          "success@1": 0.21428571428571427,
          "ndcg@1": 0.21428571428571427,
          "recall@3": 0.2857142857142857,
          "success@3": 0.2857142857142857,
          "ndcg@3": 0.25935212525510415,
          "recall@5": 0.42857142857142855,
          "success@5": 0.42857142857142855,
          "ndcg@5": 0.3177470799199566,
          "recall@10": 0.7142857142857143,
          "success@10": 0.7142857142857143,
          "ndcg@10": 0.40829494942546596,
          "mrr": 0.330415120593692,
          "num_queries": 14,
          "num_candidates": 1059
        },
        "literature": {
          "recall@1": 0.3074712643678161,
          "success@1": 0.3218390804597701,
          "ndcg@1": 0.3218390804597701,
          "recall@3": 0.5086206896551724,
          "success@3": 0.5229885057471264,
          "ndcg@3": 0.4277153536098478,
          "recall@5": 0.5804597701149425,
          "success@5": 0.5862068965517241,
          "ndcg@5": 0.45767491212643047,
          "recall@10": 0.7040229885057471,
          "success@10": 0.7068965517241379,
          "ndcg@10": 0.4975491127463419,
          "mrr": 0.44921810782319677,
          "num_queries": 174,
          "num_candidates": 1059
        },
        "social_media/economy": {
          "recall@1": 0.3333333333333333,
          "success@1": 0.3333333333333333,
          "ndcg@1": 0.3333333333333333,
          "recall@3": 0.6666666666666666,
          "success@3": 0.6666666666666666,
          "ndcg@3": 0.543643251190486,
          "recall@5": 0.6666666666666666,
          "success@5": 0.6666666666666666,
          "ndcg@5": 0.543643251190486,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6473762777990227,
          "mrr": 0.5404761904761904,
          "num_queries": 6,
          "num_candidates": 1059
        },
        "blog/advertising": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.030303030303030304,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/communications-media": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.3333333333333333,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.16666666666666666,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.16666666666666666,
          "recall@10": 0.3333333333333333,
          "success@10": 0.3333333333333333,
          "ndcg@10": 0.16666666666666666,
          "mrr": 0.13750461424880028,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/education": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.010173001949317738,
          "num_queries": 3,
          "num_candidates": 1059
        },
        "blog/engineering": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.013333333333333334,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/fashion": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.07142857142857142,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/government": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.03125,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/indunk": {
          "recall@1": 0.23076923076923078,
          "success@1": 0.23076923076923078,
          "ndcg@1": 0.23076923076923078,
          "recall@3": 0.38461538461538464,
          "success@3": 0.38461538461538464,
          "ndcg@3": 0.32783534670330117,
          "recall@5": 0.38461538461538464,
          "success@5": 0.38461538461538464,
          "ndcg@5": 0.32783534670330117,
          "recall@10": 0.46153846153846156,
          "success@10": 0.46153846153846156,
          "ndcg@10": 0.3521018756868188,
          "mrr": 0.33002486593907554,
          "num_queries": 13,
          "num_candidates": 1059
        },
        "blog/internet": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.43067655807339306,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.43067655807339306,
          "mrr": 0.25,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/military": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.018867924528301886,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/non-profit": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 1.0,
          "success@3": 1.0,
          "ndcg@3": 0.6309297535714575,
          "recall@5": 1.0,
          "success@5": 1.0,
          "ndcg@5": 0.6309297535714575,
          "recall@10": 1.0,
          "success@10": 1.0,
          "ndcg@10": 0.6309297535714575,
          "mrr": 0.5,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/science": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/student": {
          "recall@1": 0.4090909090909091,
          "success@1": 0.45454545454545453,
          "ndcg@1": 0.45454545454545453,
          "recall@3": 0.4090909090909091,
          "success@3": 0.45454545454545453,
          "ndcg@3": 0.4193770175241326,
          "recall@5": 0.5,
          "success@5": 0.5454545454545454,
          "ndcg@5": 0.45454545454545453,
          "recall@10": 0.6363636363636364,
          "success@10": 0.6363636363636364,
          "ndcg@10": 0.5055081440633189,
          "mrr": 0.5086178527354998,
          "num_queries": 11,
          "num_candidates": 1059
        },
        "blog/technology": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.04060216011422593,
          "num_queries": 4,
          "num_candidates": 1059
        },
        "blog/telecommunications": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.022727272727272728,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "blog/transportation": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.0,
          "success@10": 0.0,
          "ndcg@10": 0.0,
          "mrr": 0.0625,
          "num_queries": 1,
          "num_candidates": 1059
        },
        "ecommerce_reviews": {
          "recall@1": 0.10256410256410256,
          "success@1": 0.10256410256410256,
          "ndcg@1": 0.10256410256410256,
          "recall@3": 0.23076923076923078,
          "success@3": 0.23076923076923078,
          "ndcg@3": 0.17673818617216341,
          "recall@5": 0.3333333333333333,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.22091014084635757,
          "recall@10": 0.4358974358974359,
          "success@10": 0.4358974358974359,
          "ndcg@10": 0.2538117187724185,
          "mrr": 0.21660804765071837,
          "num_queries": 39,
          "num_candidates": 1059
        },
        "research_paper": {
          "recall@1": 0.74,
          "success@1": 0.76,
          "ndcg@1": 0.76,
          "recall@3": 0.8,
          "success@3": 0.8,
          "ndcg@3": 0.7820260217087858,
          "recall@5": 0.8,
          "success@5": 0.8,
          "ndcg@5": 0.7820260217087858,
          "recall@10": 0.84,
          "success@10": 0.84,
          "ndcg@10": 0.7962743091931067,
          "mrr": 0.7956608187134503,
          "num_queries": 25,
          "num_candidates": 1059
        },
        "social_media/investing": {
          "recall@1": 0.0,
          "success@1": 0.0,
          "ndcg@1": 0.0,
          "recall@3": 0.0,
          "success@3": 0.0,
          "ndcg@3": 0.0,
          "recall@5": 0.0,
          "success@5": 0.0,
          "ndcg@5": 0.0,
          "recall@10": 0.5,
          "success@10": 0.5,
          "ndcg@10": 0.16666666666666666,
          "mrr": 0.07692307692307691,
          "num_queries": 2,
          "num_candidates": 1059
        },
        "media_reviews/douban": {
          "recall@1": 0.10909090909090909,
          "success@1": 0.10909090909090909,
          "ndcg@1": 0.10909090909090909,
          "recall@3": 0.2,
          "success@3": 0.2,
          "ndcg@3": 0.16168707746753405,
          "recall@5": 0.24545454545454545,
          "success@5": 0.2545454545454545,
          "ndcg@5": 0.1813524863380891,
          "recall@10": 0.33636363636363636,
          "success@10": 0.34545454545454546,
          "ndcg@10": 0.21013675997195927,
          "mrr": 0.19602555983654427,
          "num_queries": 55,
          "num_candidates": 1059
        },
        "social_media/xiaohongshu": {
          "recall@1": 0.7678571428571429,
          "success@1": 0.7857142857142857,
          "ndcg@1": 0.7857142857142857,
          "recall@3": 0.8214285714285714,
          "success@3": 0.8214285714285714,
          "ndcg@3": 0.8082474911989806,
          "recall@5": 0.8214285714285714,
          "success@5": 0.8214285714285714,
          "ndcg@5": 0.8082474911989806,
          "recall@10": 0.9285714285714286,
          "success@10": 0.9285714285714286,
          "ndcg@10": 0.8429868504688997,
          "mrr": 0.8194736227824463,
          "num_queries": 28,
          "num_candidates": 1059
        }
      },
      "by_length_bucket": {
        "long": {
          "recall@1": 0.3372093023255814,
          "success@1": 0.34366925064599485,
          "ndcg@1": 0.34366925064599485,
          "recall@3": 0.5142118863049095,
          "success@3": 0.5219638242894057,
          "ndcg@3": 0.4435426389616537,
          "recall@5": 0.5736434108527132,
          "success@5": 0.5788113695090439,
          "ndcg@5": 0.4684146162817365,
          "recall@10": 0.6937984496124031,
          "success@10": 0.6950904392764858,
          "ndcg@10": 0.5072596250008973,
          "mrr": 0.4642123730953267,
          "num_queries": 387,
          "num_candidates": 1059
        },
        "medium": {
          "recall@1": 0.25334608030592737,
          "success@1": 0.26003824091778205,
          "ndcg@1": 0.26003824091778205,
          "recall@3": 0.3738049713193117,
          "success@3": 0.38049713193116635,
          "ndcg@3": 0.3256156589927449,
          "recall@5": 0.45506692160611856,
          "success@5": 0.4627151051625239,
          "ndcg@5": 0.35930072970553395,
          "recall@10": 0.5487571701720841,
          "success@10": 0.5525812619502868,
          "ndcg@10": 0.3894142439681625,
          "mrr": 0.3606157733924295,
          "num_queries": 523,
          "num_candidates": 1059
        },
        "short": {
          "recall@1": 0.22666666666666666,
          "success@1": 0.24,
          "ndcg@1": 0.24,
          "recall@3": 0.31333333333333335,
          "success@3": 0.32,
          "ndcg@3": 0.27726303318742085,
          "recall@5": 0.32666666666666666,
          "success@5": 0.3333333333333333,
          "ndcg@5": 0.283005387295066,
          "recall@10": 0.4266666666666667,
          "success@10": 0.4266666666666667,
          "ndcg@10": 0.31513970998900787,
          "mrr": 0.29968796286333427,
          "num_queries": 75,
          "num_candidates": 1059
        },
        "extra_long": {
          "recall@1": 0.2222222222222222,
          "success@1": 0.25925925925925924,
          "ndcg@1": 0.25925925925925924,
          "recall@3": 0.2962962962962963,
          "success@3": 0.3333333333333333,
          "ndcg@3": 0.282627027910054,
          "recall@5": 0.35185185185185186,
          "success@5": 0.4074074074074074,
          "ndcg@5": 0.3083583123784237,
          "recall@10": 0.5,
          "success@10": 0.5555555555555556,
          "ndcg@10": 0.3603114131410808,
          "mrr": 0.35342629307301376,
          "num_queries": 27,
          "num_candidates": 1059
        }
      }
    },
    "attribution": {
      "eer": 0.08071146245059288,
      "num_queries": 1012,
      "positive_pairs": 1061,
      "negative_pairs": 50600,
      "negatives_per_query": 50,
      "negative_strategy": "sample",
      "num_candidates": 1059,
      "by_language": {
        "ar": {
          "eer": 0.0877832512315271,
          "num_queries": 203,
          "positive_pairs": 223,
          "negative_pairs": 10150
        },
        "de": {
          "eer": 0.05555555555555555,
          "num_queries": 71,
          "positive_pairs": 72,
          "negative_pairs": 3550
        },
        "en": {
          "eer": 0.09602409638554217,
          "num_queries": 166,
          "positive_pairs": 169,
          "negative_pairs": 8300
        },
        "fr": {
          "eer": 0.04967741935483871,
          "num_queries": 62,
          "positive_pairs": 65,
          "negative_pairs": 3100
        },
        "es": {
          "eer": 0.06059405940594059,
          "num_queries": 101,
          "positive_pairs": 107,
          "negative_pairs": 5050
        },
        "hi": {
          "eer": 0.0345,
          "num_queries": 40,
          "positive_pairs": 40,
          "negative_pairs": 2000
        },
        "ja": {
          "eer": 0.011764705882352941,
          "num_queries": 17,
          "positive_pairs": 18,
          "negative_pairs": 850
        },
        "ko": {
          "eer": 0.061855670103092786,
          "num_queries": 92,
          "positive_pairs": 97,
          "negative_pairs": 4600
        },
        "ru": {
          "eer": 0.061203007518796995,
          "num_queries": 133,
          "positive_pairs": 137,
          "negative_pairs": 6650
        },
        "zh": {
          "eer": 0.06614173228346457,
          "num_queries": 127,
          "positive_pairs": 133,
          "negative_pairs": 6350
        }
      },
      "by_genre": {
        "news": {
          "eer": 0.0651985559566787,
          "num_queries": 277,
          "positive_pairs": 287,
          "negative_pairs": 13850
        },
        "poetry": {
          "eer": 0.043478260869565216,
          "num_queries": 52,
          "positive_pairs": 69,
          "negative_pairs": 2600
        },
        "social_media/politics": {
          "eer": 0.07547169811320754,
          "num_queries": 52,
          "positive_pairs": 53,
          "negative_pairs": 2600
        },
        "social_media/business": {
          "eer": 0.14285714285714285,
          "num_queries": 7,
          "positive_pairs": 7,
          "negative_pairs": 350
        },
        "social_media/sports": {
          "eer": 0.07641025641025641,
          "num_queries": 39,
          "positive_pairs": 40,
          "negative_pairs": 1950
        },
        "social_media/cryptocurrency": {
          "eer": 0.25,
          "num_queries": 7,
          "positive_pairs": 8,
          "negative_pairs": 350
        },
        "social_media/people": {
          "eer": 0.1075,
          "num_queries": 56,
          "positive_pairs": 57,
          "negative_pairs": 2800
        },
        "social_media/entertainment": {
          "eer": 0.08311111111111111,
          "num_queries": 45,
          "positive_pairs": 46,
          "negative_pairs": 2250
        },
        "social_media/environment": {
          "eer": 0.1,
          "num_queries": 20,
          "positive_pairs": 20,
          "negative_pairs": 1000
        },
        "social_media/technology": {
          "eer": 0.06896551724137931,
          "num_queries": 29,
          "positive_pairs": 29,
          "negative_pairs": 1450
        },
        "social_media/social": {
          "eer": 0.0825,
          "num_queries": 24,
          "positive_pairs": 25,
          "negative_pairs": 1200
        },
        "social_media/finance": {
          "eer": 0.064,
          "num_queries": 5,
          "positive_pairs": 5,
          "negative_pairs": 250
        },
        "social_media/health": {
          "eer": 0.068,
          "num_queries": 10,
          "positive_pairs": 10,
          "negative_pairs": 500
        },
        "social_media/law": {
          "eer": 0.02,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "social_media/science": {
          "eer": 0.06714285714285714,
          "num_queries": 14,
          "positive_pairs": 14,
          "negative_pairs": 700
        },
        "literature": {
          "eer": 0.06735632183908045,
          "num_queries": 174,
          "positive_pairs": 184,
          "negative_pairs": 8700
        },
        "social_media/economy": {
          "eer": 0.0033333333333333335,
          "num_queries": 6,
          "positive_pairs": 6,
          "negative_pairs": 300
        },
        "blog/advertising": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/communications-media": {
          "eer": 0.10666666666666667,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/education": {
          "eer": 0.14,
          "num_queries": 3,
          "positive_pairs": 3,
          "negative_pairs": 150
        },
        "blog/engineering": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/fashion": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/government": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/indunk": {
          "eer": 0.17846153846153845,
          "num_queries": 13,
          "positive_pairs": 13,
          "negative_pairs": 650
        },
        "blog/internet": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/military": {
          "eer": 0.04,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/non-profit": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/science": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/student": {
          "eer": 0.04727272727272727,
          "num_queries": 11,
          "positive_pairs": 12,
          "negative_pairs": 550
        },
        "blog/technology": {
          "eer": 0.25,
          "num_queries": 4,
          "positive_pairs": 4,
          "negative_pairs": 200
        },
        "blog/telecommunications": {
          "eer": 0.02,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "blog/transportation": {
          "eer": 0.0,
          "num_queries": 1,
          "positive_pairs": 1,
          "negative_pairs": 50
        },
        "ecommerce_reviews": {
          "eer": 0.0641025641025641,
          "num_queries": 39,
          "positive_pairs": 39,
          "negative_pairs": 1950
        },
        "research_paper": {
          "eer": 0.038461538461538464,
          "num_queries": 25,
          "positive_pairs": 26,
          "negative_pairs": 1250
        },
        "social_media/investing": {
          "eer": 0.1,
          "num_queries": 2,
          "positive_pairs": 2,
          "negative_pairs": 100
        },
        "media_reviews/douban": {
          "eer": 0.07781818181818181,
          "num_queries": 55,
          "positive_pairs": 58,
          "negative_pairs": 2750
        },
        "social_media/xiaohongshu": {
          "eer": 0.035,
          "num_queries": 28,
          "positive_pairs": 29,
          "negative_pairs": 1400
        }
      },
      "by_length_bucket": {
        "long": {
          "eer": 0.06683168316831684,
          "num_queries": 387,
          "positive_pairs": 404,
          "negative_pairs": 19350
        },
        "medium": {
          "eer": 0.07717017208413002,
          "num_queries": 523,
          "positive_pairs": 539,
          "negative_pairs": 26150
        },
        "short": {
          "eer": 0.104,
          "num_queries": 75,
          "positive_pairs": 79,
          "negative_pairs": 3750
        },
        "extra_long": {
          "eer": 0.07185185185185185,
          "num_queries": 27,
          "positive_pairs": 39,
          "negative_pairs": 1350
        }
      }
    }
  }
}